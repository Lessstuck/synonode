<!DOCTYPE html>
<html lang="en" data-rh="lang"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><title>Intro — Getting Started with Text Embeddings: Using BERT | by David Liang | Medium</title><meta data-rh="true" charset="utf-8"><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-02-28T06:27:53.925Z"><meta data-rh="true" name="title" content="Intro — Getting Started with Text Embeddings: Using BERT | by David Liang | Medium"><meta data-rh="true" property="og:title" content="Intro — Getting Started with Text Embeddings: Using BERT"><meta data-rh="true" property="al:android:url" content="medium://p/9f8c3b98dee6"><meta data-rh="true" property="al:ios:url" content="medium://p/9f8c3b98dee6"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="Contextual embeddings have revolutionized natural language processing (NLP) by providing richer, context-aware representations of text. This guide will delve deeper into the theory behind contextual…"><meta data-rh="true" property="og:description" content="Contextual embeddings have revolutionized natural language processing (NLP) by providing richer, context-aware representations of text…"><meta data-rh="true" property="og:url" content="https://medium.com/@davidlfliang/intro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6"><meta data-rh="true" property="al:web:url" content="https://medium.com/@davidlfliang/intro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6"><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1024/1*7qIA2ypzDmgjpRIQX-ICmQ.jpeg"><meta data-rh="true" property="article:author" content="https://medium.com/@davidlfliang"><meta data-rh="true" name="author" content="David Liang"><meta data-rh="true" name="robots" content="index,noarchive,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" property="twitter:title" content="Intro — Getting Started with Text Embeddings: Using BERT"><meta data-rh="true" name="twitter:site" content="@Medium"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/9f8c3b98dee6"><meta data-rh="true" property="twitter:description" content="Contextual embeddings have revolutionized natural language processing (NLP) by providing richer, context-aware representations of text…"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1024/1*7qIA2ypzDmgjpRIQX-ICmQ.jpeg"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:label1" content="Reading time"><meta data-rh="true" name="twitter:data1" content="10 min read"><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://medium.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:304:304/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:240:240/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:152:152/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:120:120/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"><link data-rh="true" rel="mask-icon" href="https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png" color="#171717"><link data-rh="true" rel="preconnect" href="https://glyph.medium.com/" crossorigin=""><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@davidlfliang"><link data-rh="true" rel="canonical" href="https://medium.com/@davidlfliang/intro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/9f8c3b98dee6"><script type="text/javascript" async="" charset="utf-8" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-0uUcqAX/lKvnfFMvCM7U5wcjfgBvv/1q+xxZKV6ZhBH4ikGcgTDEC4vEZPTt3l8O"></script><script async="" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/branch-latest.min.js"></script><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*7qIA2ypzDmgjpRIQX-ICmQ.jpeg"],"url":"https:\u002F\u002Fmedium.com\u002F@davidlfliang\u002Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6","dateCreated":"2024-07-30T10:57:18.122Z","datePublished":"2024-07-30T10:57:18.122Z","dateModified":"2025-02-28T07:28:15.208Z","headline":"Intro — Getting Started with Text Embeddings: Using BERT","name":"Intro — Getting Started with Text Embeddings: Using BERT","description":"Contextual embeddings have revolutionized natural language processing (NLP) by providing richer, context-aware representations of text. This guide will delve deeper into the theory behind contextual…","identifier":"9f8c3b98dee6","author":{"@type":"Person","name":"David Liang","url":"https:\u002F\u002Fmedium.com\u002F@davidlfliang"},"creator":["David Liang"],"publisher":{"@type":"Organization","name":"Medium","url":"https:\u002F\u002Fmedium.com\u002F","logo":{"@type":"ImageObject","width":272,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:544\u002F7*V1_7XP4snlmqrc_0Njontw.png"}},"mainEntityOfPage":"https:\u002F\u002Fmedium.com\u002F@davidlfliang\u002Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6"}</script><style type="text/css" data-fela-rehydration="575" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="575" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-webkit-keyframes k1{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}@-moz-keyframes k1{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}@keyframes k1{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{gap:16px}.ag{color:inherit}.ah{fill:inherit}.ai{font-size:inherit}.aj{border:inherit}.ak{font-family:inherit}.al{letter-spacing:inherit}.am{font-weight:inherit}.an{padding:0}.ao{margin:0}.ap{cursor:pointer}.aq:disabled{cursor:not-allowed}.ar:disabled{color:#6B6B6B}.as:disabled{fill:#6B6B6B}.av{width:auto}.aw path{fill:#242424}.ax{height:25px}.ay{border:none}.az{border-radius:20px}.ba{width:240px}.bb{background:#F9F9F9}.bc path{fill:#6B6B6B}.be{outline:none}.bf{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bg{font-size:14px}.bh{width:100%}.bi{padding:10px 20px 10px 0}.bj{background-color:transparent}.bk{color:#242424}.bl::placeholder{color:#6B6B6B}.bm{display:inline-block}.bn{margin-left:12px}.bo{margin-right:12px}.bp{border-radius:4px}.bq{margin-left:24px}.br{height:24px}.bx{background-color:#F9F9F9}.by{border-radius:50%}.bz{height:32px}.ca{width:32px}.cb{flex:0 0 auto}.cc{flex:1 1 auto}.cd{justify-content:center}.cj{max-width:680px}.ck{min-width:0}.cl{animation:k1 1.2s ease-in-out infinite}.cm{height:100vh}.cn{margin-bottom:16px}.co{margin-top:48px}.cp{align-items:flex-start}.cq{flex-direction:column}.cr{justify-content:space-between}.cs{margin-bottom:24px}.cy{width:80%}.cz{background-color:#F2F2F2}.df{height:44px}.dg{width:44px}.dh{margin:auto 0}.di{margin-bottom:4px}.dj{height:16px}.dk{width:120px}.dl{width:80px}.dr{margin-bottom:8px}.ds{width:96%}.dt{width:98%}.du{width:81%}.dv{margin-left:8px}.dw{color:#6B6B6B}.dx{font-size:13px}.dy{height:100%}.er{color:#FFFFFF}.es{fill:#FFFFFF}.et{background:#1A8917}.eu{border-color:#1A8917}.ey:disabled{cursor:inherit !important}.ez:disabled{opacity:0.3}.fa:disabled:hover{background:#1A8917}.fb:disabled:hover{border-color:#1A8917}.fc{border-radius:99em}.fd{border-width:1px}.fe{border-style:solid}.ff{box-sizing:border-box}.fg{text-decoration:none}.fh{text-align:center}.fi{margin-left:16px}.fl{margin-right:32px}.fm{position:relative}.fn{fill:#6B6B6B}.fq{background:transparent}.fr svg{margin-left:4px}.fs svg{fill:#6B6B6B}.fu{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fv{position:absolute}.gc{margin:0 24px}.gg{background:rgba(255, 255, 255, 1)}.gh{border:1px solid #F2F2F2}.gi{box-shadow:0 1px 4px #F2F2F2}.gj{max-height:100vh}.gk{overflow-y:auto}.gl{left:0}.gm{top:calc(100vh + 100px)}.gn{bottom:calc(100vh + 100px)}.go{width:10px}.gp{pointer-events:none}.gq{word-break:break-word}.gr{word-wrap:break-word}.gs:after{display:block}.gt:after{content:""}.gu:after{clear:both}.gv{line-height:1.23}.gw{letter-spacing:0}.gx{font-style:normal}.gy{font-weight:700}.id{align-items:baseline}.ie{width:48px}.if{height:48px}.ig{border:2px solid rgba(255, 255, 255, 1)}.ih{z-index:0}.ii{box-shadow:none}.ij{border:1px solid rgba(0, 0, 0, 0.05)}.ik{margin-bottom:2px}.il{flex-wrap:nowrap}.im{font-size:16px}.in{line-height:24px}.ip{margin:0 8px}.iq{display:inline}.ir{text-decoration:underline}.iu{flex-wrap:wrap}.iv{padding-left:8px}.iw{padding-right:8px}.jx> *{flex-shrink:0}.jy{overflow-x:scroll}.jz::-webkit-scrollbar{display:none}.ka{scrollbar-width:none}.kb{-ms-overflow-style:none}.kc{width:74px}.kd{flex-direction:row}.ke{z-index:2}.kf{margin-right:4px}.ki{-webkit-user-select:none}.kj{border:0}.kk{fill:rgba(117, 117, 117, 1)}.kn{outline:0}.ko{user-select:none}.kp> svg{pointer-events:none}.ky{cursor:progress}.kz{opacity:1}.la{padding:4px 0}.ld{margin-top:0px}.le{width:16px}.lg{display:inline-flex}.lm{max-width:100%}.ln{padding:8px 2px}.lo svg{color:#6B6B6B}.mf{margin-left:auto}.mg{margin-right:auto}.mh{max-width:1024px}.mn{clear:both}.mp{cursor:zoom-in}.mq{z-index:auto}.ms{height:auto}.mt{margin-top:10px}.mu{max-width:728px}.mx{line-height:1.58}.my{letter-spacing:-0.004em}.mz{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.nu{margin-bottom:-0.46em}.nv{line-height:1.12}.nw{letter-spacing:-0.022em}.nx{font-weight:600}.os{margin-bottom:-0.28em}.oy{line-height:1.18}.pm{margin-bottom:-0.31em}.pn{list-style-type:decimal}.po{margin-left:30px}.pp{padding-left:0px}.pv{list-style-type:disc}.qb{overflow-x:auto}.qc{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.qd{padding:32px}.qe{border:1px solid #E5E5E5}.qf{line-height:1.4}.qg{margin-top:-0.2em}.qh{margin-bottom:-0.2em}.qi{white-space:pre}.qj{min-width:fit-content}.qk{padding:2px 4px}.ql{font-size:75%}.qm> strong{font-family:inherit}.qn{margin-top:32px}.qo{margin-bottom:14px}.qp{padding-top:24px}.qq{padding-bottom:10px}.qr{background-color:#000000}.qs{height:3px}.qt{width:3px}.qu{margin-right:20px}.rf{box-shadow:inset 0 0 0 1px #F2F2F2}.rg{padding:0px}.rh{padding:16px 20px}.rj{overflow:hidden}.rk{max-height:40px}.rl{text-overflow:ellipsis}.rm{display:-webkit-box}.rn{-webkit-line-clamp:2}.ro{-webkit-box-orient:vertical}.rq{margin-top:8px}.rr{margin-top:12px}.rs{width:160px}.rt{background-image:url(https://miro.medium.com/v2/resize:fit:320/1*JXnjxfx0wxr5U2VFMeITgQ.png)}.ru{background-origin:border-box}.rv{background-size:cover}.rw{height:167px}.rx{background-position:50% 50%}.ry{margin-bottom:26px}.rz{margin-top:6px}.sa{margin-right:8px}.sb{padding:8px 16px}.sc{border-radius:100px}.sd{transition:background 300ms ease}.sf{white-space:nowrap}.sg{border-top:none}.sh{margin-bottom:50px}.si{height:52px}.sj{max-height:52px}.sk{box-sizing:content-box}.sl{position:static}.sm{z-index:1}.so{max-width:155px}.su{margin-bottom:64px}.tj{height:64px}.tk{width:64px}.tl{align-self:flex-end}.tm{color:rgba(255, 255, 255, 1)}.tn{fill:rgba(255, 255, 255, 1)}.to{background:rgba(25, 25, 25, 1)}.tp{border-color:rgba(25, 25, 25, 1)}.ts:disabled{opacity:0.1}.tt:disabled:hover{background:rgba(25, 25, 25, 1)}.tu:disabled:hover{border-color:rgba(25, 25, 25, 1)}.ua{padding-right:4px}.ub{font-weight:500}.ui{white-space:pre-wrap}.uj{margin-top:16px}.uk{margin-bottom:54px}.ul{height:0px}.um{gap:18px}.un{fill:rgba(61, 61, 61, 1)}.uz{border-bottom:solid 1px #E5E5E5}.va{margin-top:72px}.vb{padding:24px 0}.vc{margin-bottom:0px}.vd{margin-right:16px}.at:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.au:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.ev:hover{background:#156D12}.ew:hover{border-color:#156D12}.ex:hover{cursor:pointer}.fo:hover{color:#242424}.fp:hover{fill:#242424}.ft:hover svg{fill:#242424}.fw:hover{background-color:rgba(0, 0, 0, 0.1)}.io:hover{text-decoration:underline}.km:hover{fill:rgba(8, 8, 8, 1)}.lb:hover{fill:#000000}.lc:hover p{color:#000000}.lf:hover{color:#000000}.lp:hover svg{color:#000000}.se:hover{background-color:#F2F2F2}.ti:hover{background-color:none}.tq:hover{background:#000000}.tr:hover{border-color:#242424}.uo:hover{fill:rgba(25, 25, 25, 1)}.bd:focus-within path{fill:#242424}.kl:focus{fill:rgba(8, 8, 8, 1)}.lq:focus svg{color:#000000}.mr:focus{transform:scale(1.01)}.kq:active{border-style:none}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bw{width:64px}.ci{margin:0 64px}.cx{height:48px}.de{margin-bottom:52px}.dq{margin-bottom:48px}.eh{font-size:14px}.ei{line-height:20px}.ep{font-size:13px}.eq{padding:5px 12px}.fk{display:flex}.gb{margin-bottom:50px}.gf{max-width:680px}.ht{font-size:42px}.hu{margin-top:1.19em}.hv{margin-bottom:32px}.hw{line-height:52px}.hx{letter-spacing:-0.011em}.ic{align-items:center}.jj{border-top:solid 1px #F2F2F2}.jk{border-bottom:solid 1px #F2F2F2}.jl{margin:32px 0 0}.jm{padding:3px 8px}.jv> *{margin-right:24px}.jw> :last-child{margin-right:0}.kx{margin-top:0px}.ll{margin:0}.mm{margin-top:40px}.nq{font-size:20px}.nr{margin-top:2.14em}.ns{line-height:32px}.nt{letter-spacing:-0.003em}.oo{font-size:24px}.op{margin-top:1.95em}.oq{line-height:30px}.or{letter-spacing:-0.016em}.ox{margin-top:0.94em}.pj{margin-top:1.72em}.pk{line-height:24px}.pl{letter-spacing:0}.pu{margin-top:1.14em}.qa{margin-top:56px}.qz{margin-top:1.25em}.re{margin-top:32px}.st{display:inline-block}.sv{flex-direction:row}.sy{margin-bottom:0}.sz{margin-right:20px}.tv{max-width:500px}.ut{margin:40px 0 0}.uy{padding-top:72px}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.kw{margin-top:0px}.mv{margin-left:auto}.mw{text-align:center}.ss{display:inline-block}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.kv{margin-top:0px}.sr{display:inline-block}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.kt{margin-top:0px}.ku{margin-right:0px}.ri{padding:10px 12px 10px}.sq{display:inline-block}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.bs{width:24px}.ce{margin:0 24px}.ct{height:40px}.da{margin-bottom:44px}.dm{margin-bottom:32px}.dz{font-size:13px}.ea{line-height:20px}.ej{padding:0px 8px 1px}.fx{margin-bottom:2px}.gz{font-size:32px}.ha{margin-top:1.01em}.hb{margin-bottom:24px}.hc{line-height:38px}.hd{letter-spacing:-0.014em}.hy{align-items:flex-start}.is{flex-direction:column}.ix{margin:24px -24px 0}.iy{padding:0}.jn> *{margin-right:8px}.jo> :last-child{margin-right:24px}.kg{margin-left:0px}.kr{margin-top:0px}.ks{margin-right:0px}.lh{margin:0}.lr{border:1px solid #F2F2F2}.ls{border-radius:99em}.lt{padding:0px 16px 0px 12px}.lu{height:38px}.lv{align-items:center}.lx svg{margin-right:8px}.mi{margin-top:32px}.na{font-size:18px}.nb{margin-top:1.56em}.nc{line-height:28px}.nd{letter-spacing:-0.003em}.ny{font-size:20px}.nz{margin-top:1.2em}.oa{line-height:24px}.ob{letter-spacing:0}.ot{margin-top:0.67em}.oz{font-size:16px}.pa{margin-top:1.23em}.pq{margin-top:1.34em}.pw{margin-top:40px}.qv{margin-top:0.93em}.ra{margin-top:24px}.sp{display:inline-block}.tg{margin-bottom:20px}.th{margin-right:0}.tz{max-width:100%}.uc{font-size:24px}.ud{line-height:30px}.ue{letter-spacing:-0.016em}.up{margin:32px 0 0}.uu{padding-top:48px}.lw:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bv{width:64px}.ch{margin:0 64px}.cw{height:48px}.dd{margin-bottom:52px}.dp{margin-bottom:48px}.ef{font-size:14px}.eg{line-height:20px}.em{font-size:13px}.eo{padding:5px 12px}.fj{display:flex}.ga{margin-bottom:50px}.ge{max-width:680px}.ho{font-size:42px}.hp{margin-top:1.19em}.hq{margin-bottom:32px}.hr{line-height:52px}.hs{letter-spacing:-0.011em}.ib{align-items:center}.jf{border-top:solid 1px #F2F2F2}.jg{border-bottom:solid 1px #F2F2F2}.jh{margin:32px 0 0}.ji{padding:3px 8px}.jt> *{margin-right:24px}.ju> :last-child{margin-right:0}.lk{margin:0}.ml{margin-top:40px}.nm{font-size:20px}.nn{margin-top:2.14em}.no{line-height:32px}.np{letter-spacing:-0.003em}.ok{font-size:24px}.ol{margin-top:1.95em}.om{line-height:30px}.on{letter-spacing:-0.016em}.ow{margin-top:0.94em}.pg{margin-top:1.72em}.ph{line-height:24px}.pi{letter-spacing:0}.pt{margin-top:1.14em}.pz{margin-top:56px}.qy{margin-top:1.25em}.rd{margin-top:32px}.sw{flex-direction:row}.ta{margin-bottom:0}.tb{margin-right:20px}.tw{max-width:500px}.us{margin:40px 0 0}.ux{padding-top:72px}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bu{width:64px}.cg{margin:0 48px}.cv{height:48px}.dc{margin-bottom:52px}.do{margin-bottom:48px}.ed{font-size:13px}.ee{line-height:20px}.el{padding:0px 8px 1px}.fz{margin-bottom:50px}.gd{max-width:680px}.hj{font-size:42px}.hk{margin-top:1.19em}.hl{margin-bottom:32px}.hm{line-height:52px}.hn{letter-spacing:-0.011em}.ia{align-items:center}.jb{border-top:solid 1px #F2F2F2}.jc{border-bottom:solid 1px #F2F2F2}.jd{margin:32px 0 0}.je{padding:3px 8px}.jr> *{margin-right:24px}.js> :last-child{margin-right:0}.lj{margin:0}.mk{margin-top:40px}.ni{font-size:20px}.nj{margin-top:2.14em}.nk{line-height:32px}.nl{letter-spacing:-0.003em}.og{font-size:24px}.oh{margin-top:1.95em}.oi{line-height:30px}.oj{letter-spacing:-0.016em}.ov{margin-top:0.94em}.pd{margin-top:1.72em}.pe{line-height:24px}.pf{letter-spacing:0}.ps{margin-top:1.14em}.py{margin-top:56px}.qx{margin-top:1.25em}.rc{margin-top:32px}.sx{flex-direction:row}.tc{margin-bottom:0}.td{margin-right:20px}.tx{max-width:500px}.ur{margin:40px 0 0}.uw{padding-top:72px}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bt{width:24px}.cf{margin:0 24px}.cu{height:40px}.db{margin-bottom:44px}.dn{margin-bottom:32px}.eb{font-size:13px}.ec{line-height:20px}.ek{padding:0px 8px 1px}.fy{margin-bottom:2px}.he{font-size:32px}.hf{margin-top:1.01em}.hg{margin-bottom:24px}.hh{line-height:38px}.hi{letter-spacing:-0.014em}.hz{align-items:flex-start}.it{flex-direction:column}.iz{margin:24px 0 0}.ja{padding:0}.jp> *{margin-right:8px}.jq> :last-child{margin-right:8px}.kh{margin-left:0px}.li{margin:0}.ly{border:1px solid #F2F2F2}.lz{border-radius:99em}.ma{padding:0px 16px 0px 12px}.mb{height:38px}.mc{align-items:center}.me svg{margin-right:8px}.mj{margin-top:32px}.ne{font-size:18px}.nf{margin-top:1.56em}.ng{line-height:28px}.nh{letter-spacing:-0.003em}.oc{font-size:20px}.od{margin-top:1.2em}.oe{line-height:24px}.of{letter-spacing:0}.ou{margin-top:0.67em}.pb{font-size:16px}.pc{margin-top:1.23em}.pr{margin-top:1.34em}.px{margin-top:40px}.qw{margin-top:0.93em}.rb{margin-top:24px}.te{margin-bottom:20px}.tf{margin-right:0}.ty{max-width:100%}.uf{font-size:24px}.ug{line-height:30px}.uh{letter-spacing:-0.016em}.uq{margin:32px 0 0}.uv{padding-top:48px}.md:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="print">.sn{display:none}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.mo{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><style type="text/css" data-fela-rehydration="575" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.rp{max-height:none}</style><script async="true" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/js" data-rh="true"></script><script data-rh="true">window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-7JY7T788PK');</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener banner closeBanner closeJourney data deepview deepviewCta first init link logout removeListener setBranchViewData setIdentity track trackCommerceEvent logEvent disableTracking getBrowserFingerprintId crossPlatformIds lastAttributedTouchData setAPIResponseCallback qrCode setRequestMetaData setAPIUrl getAPIUrl setDMAParamsForEEA".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script><script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/enterprise.js" data-rh="true"></script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><div class="l c"><div class="l m n o c" style="transform: translateY(0px);"><div class="p q r s t u v w x i d y z"><a class="dw ah dx bf al b an ao ap aq ar as at au s u w i d q dy z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9f8c3b98dee6&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderUser&amp;source=post_page---top_nav_layout_nav-----------------------------------------" rel="noopener follow">Open in app<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" viewBox="0 0 10 10" class="dv"><path fill="currentColor" d="M.985 8.485a.375.375 0 1 0 .53.53zM8.75 1.25h.375A.375.375 0 0 0 8.75.875zM8.375 6.5a.375.375 0 1 0 .75 0zM3.5.875a.375.375 0 1 0 0 .75zm-1.985 8.14 7.5-7.5-.53-.53-7.5 7.5zm6.86-7.765V6.5h.75V1.25zM3.5 1.625h5.25v-.75H3.5z"></path></svg></a><div class="ab q"><p class="bf b dz ea eb ec ed ee ef eg eh ei dw"><span><button class="bf b dz ea ej eb ec ek ed ee el em eg eo ep ei eq er es et eu ev ew ex ey ez fa fb fc fd fe ff bm fg fh" data-testid="headerSignUpButton">Sign up</button></span></p><div class="fi l"><p class="bf b dz ea eb ec ed ee ef eg eh ei dw"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" data-testid="headerSignInButton" rel="noopener follow" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------">Sign in</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae af"><a class="ag ah ai aj ak al am an ao ap aq ar as at au ab" aria-label="Homepage" data-testid="headerMediumLogo" rel="noopener follow" href="https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------"><svg xmlns="http://www.w3.org/2000/svg" width="719" height="160" fill="none" viewBox="0 0 719 160" class="av aw ax"><path fill="#242424" d="m174.104 9.734.215-.047V8.02H130.39L89.6 103.89 48.81 8.021H1.472v1.666l.212.047c8.018 1.81 12.09 4.509 12.09 14.242V137.93c0 9.734-4.087 12.433-12.106 14.243l-.212.047v1.671h32.118v-1.665l-.213-.048c-8.018-1.809-12.089-4.509-12.089-14.242V30.586l52.399 123.305h2.972l53.925-126.743V140.75c-.687 7.688-4.721 10.062-11.982 11.701l-.215.05v1.652h55.948v-1.652l-.215-.05c-7.269-1.639-11.4-4.013-12.087-11.701l-.037-116.774h.037c0-9.733 4.071-12.432 12.087-14.242m25.555 75.488c.915-20.474 8.268-35.252 20.606-35.507 3.806.063 6.998 1.312 9.479 3.714 5.272 5.118 7.751 15.812 7.368 31.793zm-.553 5.77h65.573v-.275c-.186-15.656-4.721-27.834-13.466-36.196-7.559-7.227-18.751-11.203-30.507-11.203h-.263c-6.101 0-13.584 1.48-18.909 4.16-6.061 2.807-11.407 7.003-15.855 12.511-7.161 8.874-11.499 20.866-12.554 34.343q-.05.606-.092 1.212a50 50 0 0 0-.065 1.151 85.807 85.807 0 0 0-.094 5.689c.71 30.524 17.198 54.917 46.483 54.917 25.705 0 40.675-18.791 44.407-44.013l-1.886-.664c-6.557 13.556-18.334 21.771-31.738 20.769-18.297-1.369-32.314-19.922-31.042-42.395m139.722 41.359c-2.151 5.101-6.639 7.908-12.653 7.908s-11.513-4.129-15.418-11.63c-4.197-8.053-6.405-19.436-6.405-32.92 0-28.067 8.729-46.22 22.24-46.22 5.657 0 10.111 2.807 12.236 7.704zm43.499 20.008c-8.019-1.897-12.089-4.722-12.089-14.951V1.309l-48.716 14.353v1.757l.299-.024c6.72-.543 11.278.386 13.925 2.83 2.072 1.915 3.082 4.853 3.082 8.987v18.66c-4.803-3.067-10.516-4.56-17.448-4.56-14.059 0-26.909 5.92-36.176 16.672-9.66 11.205-14.767 26.518-14.767 44.278-.003 31.72 15.612 53.039 38.851 53.039 13.595 0 24.533-7.449 29.54-20.013v16.865h43.711v-1.746zM424.1 19.819c0-9.904-7.468-17.374-17.375-17.374-9.859 0-17.573 7.632-17.573 17.374s7.721 17.374 17.573 17.374c9.907 0 17.375-7.47 17.375-17.374m11.499 132.546c-8.019-1.897-12.089-4.722-12.089-14.951h-.035V43.635l-43.714 12.551v1.705l.263.024c9.458.842 12.047 4.1 12.047 15.152v81.086h43.751v-1.746zm112.013 0c-8.018-1.897-12.089-4.722-12.089-14.951V43.635l-41.621 12.137v1.71l.246.026c7.733.813 9.967 4.257 9.967 15.36v59.279c-2.578 5.102-7.415 8.131-13.274 8.336-9.503 0-14.736-6.419-14.736-18.073V43.638l-43.714 12.55v1.703l.262.024c9.459.84 12.05 4.097 12.05 15.152v50.17a56.3 56.3 0 0 0 .91 10.444l.787 3.423c3.701 13.262 13.398 20.197 28.59 20.197 12.868 0 24.147-7.966 29.115-20.43v17.311h43.714v-1.747zm169.818 1.788v-1.749l-.213-.05c-8.7-2.006-12.089-5.789-12.089-13.49v-63.79c0-19.89-11.171-31.761-29.883-31.761-13.64 0-25.141 7.882-29.569 20.16-3.517-13.01-13.639-20.16-28.606-20.16-13.146 0-23.449 6.938-27.869 18.657V43.643L545.487 55.68v1.715l.263.024c9.345.829 12.047 4.181 12.047 14.95v81.784h40.787v-1.746l-.215-.053c-6.941-1.631-9.181-4.606-9.181-12.239V66.998c1.836-4.289 5.537-9.37 12.853-9.37 9.086 0 13.692 6.296 13.692 18.697v77.828h40.797v-1.746l-.215-.053c-6.94-1.631-9.18-4.606-9.18-12.239V75.066a42 42 0 0 0-.578-7.26c1.947-4.661 5.86-10.177 13.475-10.177 9.214 0 13.691 6.114 13.691 18.696v77.828z"></path></svg></a><div class="h"><div class="ab ay az ba bb q bc bd"><div class="bm" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bn bo ab"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ay be bf bg z bh bi bj bk bl" placeholder="Search"></div></div></div><div class="h k w fj fk"><div class="fl ab"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" data-testid="headerWriteButton" rel="noopener follow" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------"><div class="bf b bg z dw fm fn ab q fo fp"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Write"><path fill="currentColor" d="M14 4a.5.5 0 0 0 0-1zm7 6a.5.5 0 0 0-1 0zm-7-7H4v1h10zM3 4v16h1V4zm1 17h16v-1H4zm17-1V10h-1v10zm-1 1a1 1 0 0 0 1-1h-1zM3 20a1 1 0 0 0 1 1v-1zM4 3a1 1 0 0 0-1 1h1z"></path><path stroke="currentColor" d="m17.5 4.5-8.458 8.458a.25.25 0 0 0-.06.098l-.824 2.47a.25.25 0 0 0 .316.316l2.47-.823a.25.25 0 0 0 .098-.06L19.5 6.5m-2-2 2.323-2.323a.25.25 0 0 1 .354 0l1.646 1.646a.25.25 0 0 1 0 .354L19.5 6.5m-2-2 2 2"></path></svg><div class="dv l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fl ab"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" data-testid="headerSearchButton" rel="noopener follow" href="https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------"><div class="bf b bg z dw fm fn ab q fo fp"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Search"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div></a></div></div><div class="fl h k j"><div class="ab q"><p class="bf b dz ea eb ec ed ee ef eg eh ei dw"><span><button class="bf b dz ea ej eb ec ek ed ee el em eg eo ep ei eq er es et eu ev ew ex ey ez fa fb fc fd fe ff bm fg fh" data-testid="headerSignUpButton">Sign up</button></span></p><div class="fi l"><p class="bf b dz ea eb ec ed ee ef eg eh ei dw"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" data-testid="headerSignInButton" rel="noopener follow" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------">Sign in</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ay fq an ab q ap fr fs ft" aria-label="user options menu" data-testid="headerUserIcon"><div class="l fm"><img alt="" class="l ff by bz ca cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"><div class="fu by l bz ca fv n ay fw"></div></div></button></div></div></div><div class="ab"><div class="cb" style="width:0"></div><div class="cc" style="width:100%"><div class="l"><div class="sn" role="dialog" aria-modal="true" tabindex="-1"><div class="ve vf bh dy vg vh vi ap vj gp vk" aria-hidden="true" role="presentation"></div><div class="vl vg vm vn vo ve dy ff vp vq vr kz vs vt vu vv vw vx vy vz wa wb ab cq wc" aria-hidden="true"><div class="wd gk"></div></div></div><div class="fx fy fz ga gb l"><div class="ab cd"><div class="ck bh gc gd ge gf"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fv gl we gn go gp"></div><div class="gq gr gs gt gu"><div class="ab cd"><div class="ck bh gc gd ge gf"><div><h1 id="f55c" class="pw-post-title gv gw gx bf gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx bk" data-testid="storyTitle" data-selectable-paragraph="">Intro — Getting Started with Text Embeddings: Using BERT</h1><div><div class="speechify-ignore ab cr"><div class="speechify-ignore bh l"><div class="hy hz ia ib ic ab"><div><div class="ab id"><div><div class="bm" aria-hidden="false" aria-describedby="1" aria-labelledby="1"><a rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---byline--9f8c3b98dee6---------------------------------------"><div class="l ie if by ig ih"><div class="l fm"><img alt="David Liang" class="l ff by df dg cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_KRQjDf-7XCRVNlpsS3QpOg_002.jpg" width="44" height="44" loading="lazy" data-testid="authorPhoto"><div class="ii by l df dg fv n ij fw"></div></div></div></a></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="ik ab q"><div class="ab q il"><div class="ab q"><div><div class="bm" aria-hidden="false" aria-describedby="2" aria-labelledby="2"><p class="bf b im in bk"><a class="ag ah ai aj ak al am an ao ap aq ar as io" data-testid="authorName" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---byline--9f8c3b98dee6---------------------------------------">David Liang</a></p></div></div></div><span class="ip iq" aria-hidden="true"><span class="bf b bg z bk">·</span></span><p class="bf b im in bk"><span><a class="ag ah ai aj ak al am an ao ap aq ar as ir" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fedc72cb1fd52&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;user=David+Liang&amp;userId=edc72cb1fd52&amp;source=post_page-edc72cb1fd52--byline--9f8c3b98dee6---------------------post_header------------------">Follow</a></span></p></div></div></span></div></div><div class="l cb"><span class="bf b bg z dw"><div class="ab cp is it iu"><span class="bf b bg z dw"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iv iw l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dw">·</span></span></div><span data-testid="storyPublishDate">Jul 30, 2024</span></div></span></div></span></div></div></div><div class="ab cr ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm"><div class="h k w fj fk q"><div class="kc l"><div class="ab q kd ke"><div class="pw-multi-vote-icon fm kf kg kh ki"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" data-testid="headerClapButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F9f8c3b98dee6&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;user=David+Liang&amp;userId=edc72cb1fd52&amp;source=---header_actions--9f8c3b98dee6---------------------clap_footer------------------"><div><div class="bm" aria-hidden="false" aria-describedby="3" aria-labelledby="3"><div class="kj ap kk kl km kn an ko kp kq ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l kr ks kt ku kv kw kx"><div><div class="bm" aria-hidden="false" aria-describedby="77" aria-labelledby="77"><p class="bf b dx z dw"><button class="ag ah ai aj ak al am an ao ap aq ar as at au xy lf">4<span class="l h g f ss st"></span></button></p></div></div></div></div></div><div><div class="bm" aria-hidden="false" aria-describedby="4" aria-labelledby="4"><button class="ap kj kz la ab q fn lb lc" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="ld"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div><div class="ab q jn jo jp jq jr js jt ju jv jw jx jy jz ka kb"><div class="le k j i d"></div><div class="h k"><div><div class="bm" aria-hidden="false" aria-describedby="5" aria-labelledby="5"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" data-testid="headerBookmarkButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f8c3b98dee6&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;source=---header_actions--9f8c3b98dee6---------------------bookmark_footer------------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="ff lg cp"><div class="l ae"><div class="ab cd"><div class="lh li lj lk ll lm ck bh"><div class="ab"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D9f8c3b98dee6&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;source=---header_actions--9f8c3b98dee6---------------------post_audio_button------------------"><div><div class="bm" aria-hidden="false" aria-describedby="49" aria-labelledby="49"><button aria-label="Listen" data-testid="audioPlayButton" class="ag fn ai aj ak al am ln ao ap aq ez lo lp lc lq lr ls lt lu s lv lw lx ly lz ma mb u mc md me"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z dw">Listen</p></div></button></div></div></a></span></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false" aria-describedby="7" aria-labelledby="7"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="ag fn ai aj ak al am ln ao ap aq ez lo lp lc lq lr ls lt lu s lv lw lx ly lz ma mb u mc md me"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z dw">Share</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mi mj mk ml mm mn mf mg paragraph-image"><div role="button" tabindex="0" class="mo mp fm mq bh mr"><div class="mf mg mh"><picture><source srcset="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_004.webp 640w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_002.webp 720w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_006.webp 750w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_007.webp 786w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_003.webp 828w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_005.webp 1100w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_007.jpg 640w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_004.jpg 720w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_003.jpg 750w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_005.jpg 786w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_002.jpg 828w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ_006.jpg 1100w, Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ.jpg 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh lm ms c" width="700" height="700" loading="eager" role="presentation" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_7qIA2ypzDmgjpRIQX-ICmQ.jpg"></picture></div></div><figcaption class="mt fh mu mf mg mv mw bf b bg z dw" data-selectable-paragraph="">The quick red fox jumps over the lazy dog.</figcaption></figure><p id="ff36" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Contextual embeddings</strong>
 have revolutionized natural language processing (NLP) by providing 
richer, context-aware representations of text. This guide will delve 
deeper into the theory behind contextual embeddings. We’ll provide a 
simple Python example and explain how to use BERT for sentence 
embeddings to perform text similarity searches.</p><h1 id="a28e" class="nv nw gx bf nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os bk" data-selectable-paragraph=""><strong class="am">1. The Concept of Embeddings</strong></h1><p id="c211" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">What is an Embedding?</strong>
 An embedding is a dense, continuous vector representation of discrete 
items, such as words or tokens. Unlike traditional methods that use 
high-dimensional, sparse representations (e.g., one-hot encoding), 
embeddings are lower-dimensional and capture semantic meaning more 
effectively.</p><p id="0d6a" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Why “Embedding”?</strong>
 The term “embedding” refers to the process of mapping discrete data 
(like words) into a continuous vector space. This “embedding” allows 
models to represent words in a way that reflects their semantic 
relationships and contextual usage. The term implies that words are 
“embedded” into a space where similar meanings are mapped closer 
together.</p><p id="61e2" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Embeddings</strong>
 enable the conversion of text into dense vectors that capture semantic 
meaning and context, facilitating tasks like text similarity search, 
classification, and language translation by providing a meaningful 
numerical representation of text.</p><h1 id="ab8f" class="nv nw gx bf nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os bk" data-selectable-paragraph="">2. BERT</h1><p id="8198" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph="">BERT
 (Bidirectional Encoder Representations from Transformers) is a 
pre-trained language model that uses bidirectional context to enhance 
performance on natural language processing tasks. Leveraging the 
Transformer architecture, it captures nuanced word meanings by 
considering context from both directions in a sentence.</p><h2 id="718d" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">2.1 Tokenization Process</h2><p id="e04b" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph="">Tokenization
 is a crucial step that occurs before the BERT model itself is applied. 
It is part of the preprocessing pipeline for preparing input text for 
BERT. Here’s a breakdown of where tokenization fits into the process:</p><ol class=""><li id="300b" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pn po pp bk" data-selectable-paragraph=""><strong class="mz gy">Text Preprocessing</strong>:
 Before any model like BERT is used, the raw text data needs to be 
processed and converted into a format suitable for the model. This 
includes tokenization.</li><li id="2bf9" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pn po pp bk" data-selectable-paragraph=""><strong class="mz gy">Tokenization</strong>: This is the step where the input text is split into smaller units, called tokens. For BERT, tokenization involves:</li></ol><ul class=""><li id="e108" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Splitting Text</strong>: Breaking down sentences into words or subword units.</li><li id="19f4" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Mapping Tokens to IDs</strong>: Converting tokens into numerical IDs based on BERT’s vocabulary.</li></ul><p id="93b8" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">3. Input Formatting</strong>: After tokenization, the tokens are converted into input formats that BERT can process. This involves:</p><ul class=""><li id="056a" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Creating Input Tensors</strong>: For BERT, this includes input IDs, attention masks, and token type IDs.</li></ul><h2 id="e4ec" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">2.2 Tokenization Process — Code Example</h2><p id="8141" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph="">Let’s use the most famous pangram<strong class="mz gy"> “The quick brown fox jumps over the lazy dog.”</strong>
 as our test input and write a simple Python code that demonstrates how 
to use the transformers library to tokenize text using a pre-trained 
BERT model.</p><p id="4e55" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Install Required Packages:</strong></p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="b50f" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph="">pip install transformers torch</span></pre><p id="1d5f" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph="">Here’s a brief overview of each package:</p><ul class=""><li id="aabd" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b"><strong class="mz gy">transformers</strong></code>: This is the Hugging Face <code class="cz qk ql qm qc b">transformers</code>
 library, it provides pre-trained models and tools for various natural 
language processing (NLP) tasks, including tokenization and model 
inference.</li><li id="26a7" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b"><strong class="mz gy">torch</strong></code>: This is the core library for PyTorch, a popular deep learning framework used for building and training neural networks.</li></ul><p id="6ed8" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Sample Code:</strong></p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="380b" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer<br><br><span class="hljs-comment"># Load BERT tokenizer</span><br>bert_tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)<br><br><span class="hljs-comment"># Example text</span><br>text = <span class="hljs-string">"The quick brown fox jumps over the lazy dog."</span><br><br><span class="hljs-comment"># Tokenize with BERT tokenizer</span><br>bert_inputs = bert_tokenizer(text, return_tensors=<span class="hljs-string">'pt'</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"Token IDs:"</span>, bert_inputs[<span class="hljs-string">'input_ids'</span>])<br><br>attention_mask = bert_inputs[<span class="hljs-string">'attention_mask'</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"Attention Mask:"</span>, attention_mask)<br><br>token_type_ids = bert_inputs[<span class="hljs-string">'token_type_ids'</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"Token Type IDs:"</span>, token_type_ids)<br><br><span class="hljs-comment"># Print the tokens themselves to understand the splits</span><br>tokens = bert_tokenizer.convert_ids_to_tokens(bert_inputs[<span class="hljs-string">'input_ids'</span>][<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"Tokens:"</span>, tokens)</span></pre><p id="7fb5" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph="">Output:</p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="d09a" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph="">Token IDs: tensor([[  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,<br>          1012,   102]])<br>Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])<br>Token Type IDs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])<br>Tokens: ['[CLS]', 'the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.', '[SEP]']</span></pre><h2 id="88f1" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">2.3 Tokenization Process — Code Explanation:</h2><ul class=""><li id="0758" class="mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b"><strong class="mz gy">BertTokenizer.from_pretrained('bert-base-uncased'): </strong></code>specifies the BERT base model with lowercase tokens.</li><li id="d630" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b"><strong class="mz gy">bert_tokenizer(text, return_tensors='pt')</strong></code>: Tokenizes the input text and returns tensors formatted for PyTorch (<code class="cz qk ql qm qc b">'pt'</code>).</li><li id="d45b" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b"><strong class="mz gy">bert_inputs['input_ids']</strong></code>: Contains the numerical IDs corresponding to each token in the input text.</li><li id="6da3" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b"><strong class="mz gy">bert_inputs['attention_mask']</strong></code>: Indicates which tokens should be attended to (1) and which should be ignored (0).</li><li id="cce2" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b"><strong class="mz gy">bert_inputs['token_type_ids']</strong></code>:
 Used to distinguish between different segments of text (e.g., in 
question-answering tasks). For a single sentence, this is typically all 
zeros.</li><li id="bf11" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b"><strong class="mz gy">bert_tokenizer.convert_ids_to_tokens(bert_inputs['input_ids'][0])</strong></code>: Converts token IDs back into human-readable tokens to visualize the tokenization process.</li></ul><h2 id="95b6" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">2.4 Embedding Generation</h2><p id="b9dd" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph="">Embedding
 generation occurs after tokenization, where tokenized inputs are 
processed by the model to produce dense vector representations capturing
 contextual meaning.</p><h2 id="5b8c" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">2.5 Embedding Generation — Code Example</h2><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="8e97" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertModel<br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># Load pre-trained model and tokenizer</span><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)<br>model = BertModel.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)<br><br><span class="hljs-comment"># Define the text</span><br>text = <span class="hljs-string">"The quick brown fox jumps over the lazy dog."</span><br><br><span class="hljs-comment"># Tokenize the text</span><br>inputs = tokenizer(text, return_tensors=<span class="hljs-string">'pt'</span>)<br><br><span class="hljs-comment"># Obtain the embeddings</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    outputs = model(**inputs)<br><br><span class="hljs-comment"># Extract the last hidden state (embeddings)</span><br>last_hidden_states = outputs.last_hidden_state<br><br><span class="hljs-comment"># Print the dimensions of the embeddings</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"Shape of the last hidden state (embeddings):"</span>, last_hidden_states.shape)<br><br><span class="hljs-comment"># Print embeddings for each token along with their vector dimension</span><br>tokens = tokenizer.convert_ids_to_tokens(inputs[<span class="hljs-string">'input_ids'</span>][<span class="hljs-number">0</span>])<br><span class="hljs-keyword">for</span> token, embedding <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(tokens, last_hidden_states[<span class="hljs-number">0</span>]):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Token: <span class="hljs-subst">{token}</span>, Embedding Dimension: <span class="hljs-subst">{embedding.shape}</span>, Embedding (first 5 components): <span class="hljs-subst">{embedding[:<span class="hljs-number">5</span>]}</span>..."</span>)  <span class="hljs-comment"># Display first 5 components for brevity</span></span></pre><p id="0a55" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph="">Output:</p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="afc4" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph="">Shape of the last hidden state (embeddings): torch.Size([1, 12, 768])<br>Token: [CLS], Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.3608,  0.2271, -0.3030, -0.1880,  0.0475])...<br>Token: the, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.3276, -0.3762, -0.5044,  0.0098,  0.9037])...<br>Token: quick, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.4000, -0.4212,  0.4903,  0.0033,  0.4567])...<br>Token: brown, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.1209, -0.2728,  0.5550, -0.1874,  0.7759])...<br>Token: fox, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.0323, -0.2305, -0.1756, -0.1121,  0.5692])...<br>Token: jumps, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.2432, -0.0648,  0.3022,  0.2046,  0.7072])...<br>Token: over, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.3485,  0.2208,  0.1372, -0.2754,  0.4551])...<br>Token: the, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.4386, -0.4292,  0.0082,  0.0577,  0.5005])...<br>Token: lazy, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([0.0259, 0.1114, 0.7189, 0.1787, 0.0898])...<br>Token: dog, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([0.6786, 0.0645, 0.2290, 0.3369, 0.0735])...<br>Token: ., Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.1088, -0.1644, -0.2961, -0.1514,  0.1527])...<br>Token: [SEP], Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.7099,  0.4367, -0.4851,  0.1776,  0.1749])...</span></pre><h2 id="edf8" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">Code Walkthrough</h2><p id="c6f8" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">2.5.1 Import Libraries</strong>:</p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="94d4" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertModel<br><span class="hljs-keyword">import</span> torch</span></pre><ul class=""><li id="1fe2" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b">BertTokenizer</code> and <code class="cz qk ql qm qc b">BertModel</code> from <code class="cz qk ql qm qc b">transformers</code> are used to handle tokenization and obtain embeddings.</li><li id="81d5" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b">torch</code> is used for tensor operations.</li></ul><p id="bbb4" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">2.5.2 Load Pre-trained Model and Tokenizer</strong>:</p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="78f3" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Load pre-trained model and tokenizer</span><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)<br>model = BertModel.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)</span></pre><ul class=""><li id="192e" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">The <code class="cz qk ql qm qc b">BertTokenizer</code> and <code class="cz qk ql qm qc b">BertModel</code> are initialized with the <code class="cz qk ql qm qc b">'bert-base-uncased'</code> configuration.</li></ul><p id="03ad" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">2.5.3 Define and Tokenize Text</strong>:</p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="fb04" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Define the text</span><br>text = <span class="hljs-string">"The quick brown fox jumps over the lazy dog."</span><br><br><span class="hljs-comment"># Tokenize the text</span><br>inputs = tokenizer(text, return_tensors=<span class="hljs-string">'pt'</span>)</span></pre><ul class=""><li id="405f" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">The text “The quick brown fox jumps over the lazy dog.” is tokenized into tokens suitable for BERT.</li><li id="207c" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b">'pt'</code> is used to indicate that tensors should be returned in PyTorch format</li></ul><p id="3ab5" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">2.5.4 Obtain Embeddings</strong>:</p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="96be" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Obtain the embeddings</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    outputs = model(**inputs)<br><br><span class="hljs-comment"># Extract the last hidden state (embeddings)</span><br>last_hidden_states = outputs.last_hidden_state</span></pre><ul class=""><li id="b88f" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">The model computes embeddings for the tokenized input text. The <code class="cz qk ql qm qc b">torch.no_grad()</code> context is used to avoid gradient calculations, which are not needed during inference.</li><li id="59ee" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Model Output</strong>: When you pass tokenized input through the model with <code class="cz qk ql qm qc b">outputs = model(**inputs)</code>, the model returns an object that contains several pieces of information, including the last hidden state.</li><li id="39a7" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b"><strong class="mz gy">outputs.last_hidden_state</strong></code>:
 This is an attribute of the model output object that contains the 
hidden states from the last layer of the model. For BERT, this will be a
 tensor where each token in the input sequence has a vector 
representation.</li></ul><p id="8063" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">2.5.5 Print Embeddings</strong>:</p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="ead3" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Print the dimensions of the embeddings</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"Shape of the last hidden state (embeddings):"</span>, last_hidden_states.shape)<br><br><span class="hljs-comment"># Print embeddings for each token along with their vector dimension</span><br>tokens = tokenizer.convert_ids_to_tokens(inputs[<span class="hljs-string">'input_ids'</span>][<span class="hljs-number">0</span>])<br><span class="hljs-keyword">for</span> token, embedding <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(tokens, last_hidden_states[<span class="hljs-number">0</span>]):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Token: <span class="hljs-subst">{token}</span>, Embedding Dimension: <span class="hljs-subst">{embedding.shape}</span>, Embedding (first 5 components): <span class="hljs-subst">{embedding[:<span class="hljs-number">5</span>]}</span>..."</span>)  <span class="hljs-comment"># Display first 5 components for brevity</span></span></pre><ul class=""><li id="b4cd" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">The
 shape of the embeddings is displayed to indicate their dimensions. 
Since we’re using the BERT base model, the vector dimension is <strong class="mz gy">768</strong>.</li><li id="2e15" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph="">For
 each token in the text, the corresponding embedding is printed along 
with its dimension and the first 5 components of the embedding vector 
for brevity.</li></ul><h1 id="d6ae" class="nv nw gx bf nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os bk" data-selectable-paragraph=""><strong class="am">3. Embedding Types</strong></h1><p id="efa7" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph="">In natural language processing (NLP), <strong class="mz gy">Word Embeddings</strong> and <strong class="mz gy">Sentence Embeddings</strong>
 represent two different approaches to capturing semantic information 
from text. In section 2.5 “Embedding Generation — Code Example”, the 
final outputs consist of word embeddings.</p><p id="3e8d" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph="">Here’s a brief comparison of the two and their use cases:</p><h2 id="832c" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">3.1 Word Embeddings</h2><ul class=""><li id="9ee4" class="mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Word embeddings</strong> are dense vector representations of individual words. They encode semantic properties and relationships between words.</li></ul><p id="5125" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Use Cases of Word Embeddings</strong></p><ul class=""><li id="9504" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Token classification (e.g., named entity recognition).</li><li id="cc2d" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph="">Contextualizing individual words in a sentence.</li></ul><h2 id="8b3c" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">3.2 Sentence Embeddings</h2><ul class=""><li id="702a" class="mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Sentence embeddings</strong>
 are dense vector representations of entire sentences or documents. They
 aim to capture the overall meaning of the text rather than individual 
words.</li></ul><p id="66dd" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Use Cases of Sentence Embeddings</strong></p><ul class=""><li id="4368" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Text similarity search.</li><li id="0ad6" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph="">Sentence classification.</li><li id="da54" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph="">Document retrieval.</li><li id="993f" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph="">Semantic textual similarity.</li></ul><h2 id="a12b" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">3.3 Methods for Obtaining Sentence Embeddings</h2><p id="ef01" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph="">In sentence embeddings, the goal is to represent an entire sentence or document with <strong class="mz gy">a single vector</strong>. This can be achieved through various methods.</p><ol class=""><li id="8879" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pn po pp bk" data-selectable-paragraph=""><strong class="mz gy">Mean Pooling</strong>:</li></ol><ul class=""><li id="70fc" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Average the embeddings of all tokens in the sentence to get a single vector representation.</li></ul><p id="8e71" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">2. [CLS] Token Embedding</strong>:</p><ul class=""><li id="202a" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Use the embedding of the <code class="cz qk ql qm qc b">[CLS]</code> token from models like BERT as the sentence representation.</li></ul><p id="c23c" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">3. Pre-trained Sentence Embedding Models</strong>:</p><ul class=""><li id="f1a2" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Models like Sentence-BERT (SBERT) are specifically designed to generate high-quality sentence embeddings.</li></ul><h2 id="2a64" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">3.4 In a Nutshell</h2><ul class=""><li id="8bc0" class="mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Word Embeddings</strong>: Represent individual tokens and are useful for tasks at the token level.</li><li id="baab" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Sentence Embeddings</strong>:
 Represent entire sentences or documents, providing a holistic view of 
the text, and are used for higher-level text analysis tasks.</li></ul><p id="1210" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph="">In this article, we focus on <strong class="mz gy">text similarity search</strong>, so let’s explore how to achieve this next.</p><h1 id="366e" class="nv nw gx bf nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os bk" data-selectable-paragraph="">4. Text Similarity Search</h1><h2 id="6a67" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">Code Example</h2><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="989b" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertModel<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.metrics.pairwise <span class="hljs-keyword">import</span> cosine_similarity<br><br><span class="hljs-comment"># Load pre-trained model and tokenizer</span><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)<br>model = BertModel.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title.function">get_sentence_embedding</span>(<span class="hljs-params">text</span>):<br>    inputs = tokenizer(text, return_tensors=<span class="hljs-string">'pt'</span>)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        outputs = model(**inputs)<br>    last_hidden_states = outputs.last_hidden_state<br>    sentence_embedding = torch.mean(last_hidden_states, dim=<span class="hljs-number">1</span>).numpy()<br>    <span class="hljs-keyword">return</span> sentence_embedding<br><br><span class="hljs-comment"># Example texts</span><br>texts = [<br>    <span class="hljs-string">"The quick brown fox jumps over the lazy dog."</span>,<br>    <span class="hljs-string">"A fast brown fox leaps over a sleepy dog."</span>,<br>    <span class="hljs-string">"This sentence is completely different from the others."</span><br>]<br><br><span class="hljs-comment"># Generate embeddings for texts</span><br>embeddings = [get_sentence_embedding(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts]<br><br><span class="hljs-comment"># Query text</span><br>query_text = <span class="hljs-string">"The quick red fox jumps over the lazy dog."</span><br>query_embedding = get_sentence_embedding(query_text)<br><br><span class="hljs-comment"># Compute cosine similarities</span><br>similarities = cosine_similarity(query_embedding, np.vstack(embeddings))<br><br><span class="hljs-comment"># Print query text</span><br><span class="hljs-built_in">print</span> (<span class="hljs-string">f"Query text: <span class="hljs-subst">{query_text}</span>"</span>)<br><br><span class="hljs-comment"># Print similarities</span><br><span class="hljs-keyword">for</span> i, text <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(texts):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Similarity with '<span class="hljs-subst">{text}</span>': <span class="hljs-subst">{similarities[<span class="hljs-number">0</span>][i]}</span>"</span>)</span></pre><p id="0467" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph="">Output:</p><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="d4f6" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph="">Query text: The quick red fox jumps over the lazy dog.<br>Similarity with 'The quick brown fox jumps over the lazy dog.': 0.9852557182312012<br>Similarity with 'A fast brown fox leaps over a sleepy dog.': 0.9026964902877808<br>Similarity with 'This sentence is completely different from the others.': 0.48106062412261963</span></pre><h2 id="4af2" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">Code Walkthrough</h2><h2 id="f31c" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph=""><strong class="am">4.1 Imports Libraries</strong>:</h2><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="b3df" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertModel<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.metrics.pairwise <span class="hljs-keyword">import</span> cosine_similarity</span></pre><ul class=""><li id="c1d8" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b">BertTokenizer</code> and <code class="cz qk ql qm qc b">BertModel</code> from <code class="cz qk ql qm qc b">transformers</code> for tokenization and embedding generation.</li><li id="72f3" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b">torch</code> for tensor operations.</li><li id="e9d8" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><code class="cz qk ql qm qc b">numpy</code> and <code class="cz qk ql qm qc b">cosine_similarity</code> from <code class="cz qk ql qm qc b">sklearn</code> for similarity calculations.</li></ul><h2 id="96bc" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph=""><strong class="am">4.2 Load Pre-trained Model</strong>:</h2><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="1ebc" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Load pre-trained BERT model and tokenizer</span><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)<br>model = BertModel.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)</span></pre><ul class=""><li id="cae7" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Initializes BERT tokenizer and model.</li><li id="96d4" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph="">BERT base model (uncased) is used.</li></ul><h2 id="116d" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph=""><strong class="am">4.3 Define </strong><code class="cz qk ql qm qc b"><strong class="am">get_sentence_embedding</strong></code><strong class="am"> Function</strong>:</h2><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="1a8b" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Function to get sentence embedding</span><br><span class="hljs-keyword">def</span> <span class="hljs-title.function">get_sentence_embedding</span>(<span class="hljs-params">text</span>):<br>    inputs = tokenizer(text, return_tensors=<span class="hljs-string">'pt'</span>)  <span class="hljs-comment"># Tokenize and prepare input tensors</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># Disable gradient calculation</span><br>        outputs = model(**inputs)  <span class="hljs-comment"># Get model outputs</span><br>    last_hidden_states = outputs.last_hidden_state  <span class="hljs-comment"># Extract last hidden states</span><br>    sentence_embedding = torch.mean(last_hidden_states, dim=<span class="hljs-number">1</span>).numpy()  <span class="hljs-comment"># Average token embeddings</span><br>    <span class="hljs-keyword">return</span> sentence_embedding</span></pre><ul class=""><li id="bc03" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Takes a text input, tokenizes it, and generates embeddings.</li><li id="92c8" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph="">Averages the token embeddings to produce a sentence embedding, using <strong class="mz gy">Mean Pooling method.</strong></li></ul><h2 id="eb6f" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph=""><strong class="am">4.4 Generate Embeddings from a list of sentences:</strong></h2><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="ba8c" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Example sentences</span><br>texts = [<br>    <span class="hljs-string">"The quick brown fox jumps over the lazy dog."</span>,<br>    <span class="hljs-string">"A fast brown fox leaps over a sleepy dog."</span>,<br>    <span class="hljs-string">"This sentence is completely different from the others."</span><br>]<br><br><span class="hljs-comment"># Generate embeddings for each example sentence</span><br>embeddings = [get_sentence_embedding(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts]</span></pre><ul class=""><li id="5f75" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Computes embeddings for each sentence in the list.</li></ul><h2 id="67cc" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph=""><strong class="am">4.5 Set Query Text and Compute the</strong> Embedding:</h2><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="f817" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Query sentence</span><br>query_text = <span class="hljs-string">"The quick red fox jumps over the lazy dog."</span><br>query_embedding = get_sentence_embedding(query_text)</span></pre><h2 id="786c" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph=""><strong class="am">4.6 Compute Cosine Similarities</strong>:</h2><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="20f1" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Compute cosine similarities between query and example sentences</span><br>similarities = cosine_similarity(query_embedding, np.vstack(embeddings))</span></pre><ul class=""><li id="e6bb" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Measures the similarity between the query embedding and each sentence embedding.</li><li id="e600" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph="">The
 cosine distance method is used to measure the distance or similarity 
between two vectors based on the cosine of the angle between them. It is
 commonly employed in text similarity and clustering tasks due to its 
effectiveness in handling high-dimensional data.</li></ul><h2 id="7e58" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph=""><strong class="am">4.7 Print Results</strong>:</h2><pre class="pw px py pz qa qb qc qd bp qe bb bk"><span id="dbe7" class="qf nw gx qc b bg qg qh l qi qj" data-selectable-paragraph=""><span class="hljs-comment"># Print query text</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f"Query text: <span class="hljs-subst">{query_text}</span>"</span>)<br><br><span class="hljs-comment"># Print similarity scores</span><br><span class="hljs-keyword">for</span> i, text <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(texts):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Similarity with '<span class="hljs-subst">{text}</span>': <span class="hljs-subst">{similarities[<span class="hljs-number">0</span>][i]}</span>"</span>)</span></pre><ul class=""><li id="7d6b" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph="">Displays the query text and its similarity scores with the example sentences.</li></ul><h1 id="af63" class="nv nw gx bf nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os bk" data-selectable-paragraph="">5. Model Size and Vector Dimension</h1><p id="8909" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Model Size</strong> and <strong class="mz gy">Vector Dimension</strong>
 are key aspects in understanding the capabilities and computational 
requirements of modern NLP models like GPT, BERT, and similar 
architectures.</p><h2 id="75bd" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">5.1 Model Size</h2><ul class=""><li id="7f88" class="mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Definition</strong>:
 Model size refers to the total number of parameters in a machine 
learning model. Parameters are the elements of the model that are 
learned from the training data, including weights and biases. The model 
size directly impacts its capacity to learn from and generalize to new 
data.</li></ul><p id="a178" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Examples</strong>:</p><ul class=""><li id="c0a4" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">BERT</strong>:
 The base model has 110 million parameters, while the large model has 
340 million parameters. These parameters allow BERT to learn nuanced 
language representations across various contexts.</li><li id="fb3c" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">GPT-3</strong>:
 With 175 billion parameters, GPT-3 represents one of the largest models
 to date, capable of generating highly coherent and contextually 
relevant text across a wide range of topics.</li></ul><h2 id="2ed7" class="oy nw gx bf nx oz pa ea ob pb pc ec of ni pd pe pf nm pg ph pi nq pj pk pl pm bk" data-selectable-paragraph="">5.2 Vector Dimension</h2><ul class=""><li id="9033" class="mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">Definition</strong>:
 Vector dimension refers to the length of the vectors used to represent 
tokens, sentences, or documents in the model’s embedding space. This 
dimension determines the number of features or attributes captured in 
the embedding vectors.</li></ul><p id="b261" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph=""><strong class="mz gy">Examples</strong>:</p><ul class=""><li id="7e8d" class="mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">BERT</strong>:
 The base model produces 768-dimensional embeddings for each token, 
while the large model produces 1024-dimensional embeddings. This 
dimensionality helps capture detailed contextual information for each 
token in the text.</li><li id="1cc6" class="mx my gx mz b na pq nc nd ne pr ng nh ni ps nk nl nm pt no np nq pu ns nt nu pv po pp bk" data-selectable-paragraph=""><strong class="mz gy">GPT-3</strong>:
 Uses 12288-dimensional embeddings for its internal representations, 
reflecting its capacity to model complex language patterns and contexts.</li></ul><h1 id="37c9" class="nv nw gx bf nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os bk" data-selectable-paragraph="">6. Steps After Text Embedding Generation</h1><p id="6bf4" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph="">After generating embeddings with a pre-trained model, further steps are needed for practical application in <strong class="mz gy">real-world scenarios</strong>. These steps include <strong class="mz gy">preparing datasets</strong>, <strong class="mz gy">indexing embeddings</strong> for efficient retrieval, using <strong class="mz gy">vector databases</strong> for storage and <strong class="mz gy">vector search</strong>, deploying the model, and performing ongoing maintenance.</p><p id="e660" class="pw-post-body-paragraph mx my gx mz b na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu gq bk" data-selectable-paragraph="">In <strong class="mz gy">upcoming articles</strong>, we will explore these topics in greater detail.</p><h1 id="3790" class="nv nw gx bf nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os bk" data-selectable-paragraph="">Summary</h1><p id="4980" class="pw-post-body-paragraph mx my gx mz b na ot nc nd ne ou ng nh ni ov nk nl nm ow no np nq ox ns nt nu gq bk" data-selectable-paragraph="">Contextual
 embeddings have revolutionized NLP by providing richer text 
representations. This guide explains the theory behind embeddings, 
tokenization, and generating embeddings with models like BERT. It also 
covers methods for obtaining sentence embeddings and the impact of model
 size and vector dimensions. Further steps, including <strong class="mz gy">dataset preparation</strong> and <strong class="mz gy">vector database search</strong>, are crucial for real-world applications, which will be explored in future articles.</p></div></div></div><div class="ab cd qn qo qp qq" role="separator"><span class="qr by bm qs qt qu"></span><span class="qr by bm qs qt qu"></span><span class="qr by bm qs qt"></span></div><div class="gq gr gs gt gu"><div class="ab cd"><div class="ck bh gc gd ge gf"><h1 id="9c28" class="nv nw gx bf nx ny qv oa ob oc qw oe of og qx oi oj ok qy om on oo qz oq or os bk" data-selectable-paragraph="">You May Also Like</h1><div class="ra rb rc rd re rf"><a rel="noopener follow" target="_blank" href="https://medium.com/@davidlfliang/guide-getting-started-with-cursor-and-deepseek-r1-710a75138566?source=post_page-----9f8c3b98dee6---------------------------------------"><div class="rg ab cb"><div class="rh ab cq cd cc ri"><h2 class="bf gy im z rj rk rl rm rn ro rp gw bk">Guide — Getting Started with Cursor and DeepSeek R1</h2><div class="rq l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">First Steps in AI-Powered Coding: A Beginner’s Guide</h3></div><div class="rr l"><p class="bf b dx z rj rk rl rm rn ro rp dw">medium.com</p></div></div><div class="rs l"><div class="rt l ru rv rw rs rx lm rf"></div></div></div></a></div></div></div></div></div></section></div></div></article></div><div class="ab cd"><div class="ck bh gc gd ge gf"><div class="ry rz ab iu"><div class="rq ab"><a class="sa ay an ap" rel="noopener follow" href="https://medium.com/tag/bert?source=post_page-----9f8c3b98dee6---------------------------------------"><div class="sb fm cz sc gh sd se bf b bg z bk sf">Bert</div></a></div><div class="rq ab"><a class="sa ay an ap" rel="noopener follow" href="https://medium.com/tag/text-embedding?source=post_page-----9f8c3b98dee6---------------------------------------"><div class="sb fm cz sc gh sd se bf b bg z bk sf">Text Embedding</div></a></div><div class="rq ab"><a class="sa ay an ap" rel="noopener follow" href="https://medium.com/tag/python?source=post_page-----9f8c3b98dee6---------------------------------------"><div class="sb fm cz sc gh sd se bf b bg z bk sf">Python</div></a></div><div class="rq ab"><a class="sa ay an ap" rel="noopener follow" href="https://medium.com/tag/vector-search?source=post_page-----9f8c3b98dee6---------------------------------------"><div class="sb fm cz sc gh sd se bf b bg z bk sf">Vector Search</div></a></div><div class="rq ab"><a class="sa ay an ap" rel="noopener follow" href="https://medium.com/tag/similarity-search?source=post_page-----9f8c3b98dee6---------------------------------------"><div class="sb fm cz sc gh sd se bf b bg z bk sf">Similarity Search</div></a></div></div></div></div><div class="l"></div><footer class="sg sh si sj sk ab q sl sm c"><div class="l ae"><div class="ab cd"><div class="ck bh gc gd ge gf"><div class="ab cr sn"><div class="ab q kd"><div class="so l"><span class="l sp sq sr e d"><div class="ab q kd ke"><div class="pw-multi-vote-icon fm kf kg kh ki"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" data-testid="footerClapButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F9f8c3b98dee6&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;user=David+Liang&amp;userId=edc72cb1fd52&amp;source=---footer_actions--9f8c3b98dee6---------------------clap_footer------------------"><div><div class="bm" aria-hidden="false" aria-describedby="8" aria-labelledby="8"><div class="kj ap kk kl km kn an ko kp kq ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l kr ks kt ku kv kw kx"><div><div class="bm" aria-hidden="false" aria-describedby="83" aria-labelledby="83"><p class="bf b dx z dw"><button class="ag ah ai aj ak al am an ao ap aq ar as at au xy lf">4<span class="l h g f ss st"></span></button></p></div></div></div></div></span><span class="l h g f ss st"><div class="ab q kd ke"><div class="pw-multi-vote-icon fm kf kg kh ki"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" data-testid="footerClapButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F9f8c3b98dee6&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;user=David+Liang&amp;userId=edc72cb1fd52&amp;source=---footer_actions--9f8c3b98dee6---------------------clap_footer------------------"><div><div class="bm" aria-hidden="false" aria-describedby="9" aria-labelledby="9"><div class="kj ap kk kl km kn an ko kp kq ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l kr ks kt ku kv kw kx"><div><div class="bm" aria-hidden="false" aria-describedby="85" aria-labelledby="85"><p class="bf b dx z dw"><button class="ag ah ai aj ak al am an ao ap aq ar as at au xy lf">4</button></p></div></div></div></div></span></div><div class="bq ab"><div><div class="bm" aria-hidden="false" aria-describedby="10" aria-labelledby="10"><button class="ap kj kz la ab q fn lb lc" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="ld"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div></div><div class="ab q"><div class="qu l cb"><div><div class="bm" aria-hidden="false" aria-describedby="11" aria-labelledby="11"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" data-testid="footerBookmarkButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f8c3b98dee6&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;source=---footer_actions--9f8c3b98dee6---------------------bookmark_footer------------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="qu l cb"><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false" aria-describedby="12" aria-labelledby="12"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="ag fn ai aj ak al am ln ao ap aq ez lo lp lc lq"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="su l"><div class="ab cd"><div class="ck bh gc gd ge gf"><div class="ab sv sw sx it is"><div class="sy sz ta tb tc td te tf tg th ab cr"><div class="h k"><a tabindex="0" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---post_author_info--9f8c3b98dee6---------------------------------------"><div class="l fm"><img alt="David Liang" class="l ff by if ie cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_KRQjDf-7XCRVNlpsS3QpOg.jpg" width="48" height="48" loading="lazy"><div class="fu by l if ie fv n ay ti"></div></div></a></div><div class="j i d"><a tabindex="0" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---post_author_info--9f8c3b98dee6---------------------------------------"><div class="l fm"><img alt="David Liang" class="l ff by tj tk cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_KRQjDf-7XCRVNlpsS3QpOg_004.jpg" width="64" height="64" loading="lazy"><div class="fu by l tj tk fv n ay ti"></div></div></a></div><div class="j i d tl cb"><div class="ab"><span><button class="bf b bg z tm sb tn to tp tq tr ex ey ts tt tu fc fd fe ff bm fg fh">Follow</button></span></div></div></div><div class="ab cq cc"><div class="tv tw tx ty tz l"><a class="ag ah ai ak al am an ao ap aq ar as at au ab q" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---post_author_info--9f8c3b98dee6---------------------------------------"><h2 class="pw-author-name bf ub uc ud ue uf ug uh ni pe pf nm ph pi nq pk pl bk"><span class="gq ua">Written by <!-- -->David Liang</span></h2></a><div class="rq ab id"><div class="l cb"><span class="pw-follower-count bf b bg z dw"><a class="ag ah ai aj ak al am an ao ap aq ar as io" rel="noopener follow" href="https://medium.com/@davidlfliang/followers?source=post_page---post_author_info--9f8c3b98dee6---------------------------------------">103 Followers</a></span></div><div class="bf b bg z dw ab ui"><span class="ip l" aria-hidden="true"><span class="bf b bg z dw">·</span></span><a class="ag ah ai aj ak al am an ao ap aq ar as io" rel="noopener follow" href="https://medium.com/@davidlfliang/following?source=post_page---post_author_info--9f8c3b98dee6---------------------------------------">13 Following</a></div></div><div class="uj l"><p class="bf b bg z bk"><span class="gq">Full Stack AI/Data Engineer - Architecting integrated solutions across full-stack development and advanced AI/data engineering.</span></p></div></div></div><div class="h k"><div class="ab"><span><button class="bf b bg z tm sb tn to tp tq tr ex ey ts tt tu fc fd fe ff bm fg fh">Follow</button></span></div></div></div></div></div></div><div class="uk l"><div class="ul bh r su"></div><div class="ab cd"><div class="ck bh gc gd ge gf"><div class="ab q cr"><h2 class="bf ub ny oa ob oc oe of og oi oj ok om on oo oq or bk">No responses yet</h2><div class="ab um"><div><div class="bm" aria-hidden="false" aria-describedby="13" aria-labelledby="13"><a class="un uo" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--9f8c3b98dee6---------------------------------------" rel="noopener follow" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 25 25"><path fill-rule="evenodd" d="M11.987 5.036a.754.754 0 0 1 .914-.01c.972.721 1.767 1.218 2.6 1.543.828.322 1.719.485 2.887.505a.755.755 0 0 1 .741.757c-.018 3.623-.43 6.256-1.449 8.21-1.034 1.984-2.662 3.209-4.966 4.083a.75.75 0 0 1-.537-.003c-2.243-.874-3.858-2.095-4.897-4.074-1.024-1.951-1.457-4.583-1.476-8.216a.755.755 0 0 1 .741-.757c1.195-.02 2.1-.182 2.923-.503.827-.322 1.6-.815 2.519-1.535m.468.903c-.897.69-1.717 1.21-2.623 1.564-.898.35-1.856.527-3.026.565.037 3.45.469 5.817 1.36 7.515.884 1.684 2.25 2.762 4.284 3.571 2.092-.81 3.465-1.89 4.344-3.575.886-1.698 1.299-4.065 1.334-7.512-1.149-.039-2.091-.217-2.99-.567-.906-.353-1.745-.873-2.683-1.561m-.009 9.155a2.672 2.672 0 1 0 0-5.344 2.672 2.672 0 0 0 0 5.344m0 1a3.672 3.672 0 1 0 0-7.344 3.672 3.672 0 0 0 0 7.344m-1.813-3.777.525-.526.916.917 1.623-1.625.526.526-2.149 2.152z" clip-rule="evenodd"></path></svg></a></div></div></div></div><div class="up uq ur us ut l"><div><div class="bf b bg z bk"><div class="in"><div class="wn l"><div class="wo ab q"><div class="l fm"><img alt="" class="l ff by bz ca cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"><div class="fu by l bz ca fv n ay ti"></div></div><div class="bn ab cp cq cd"><p class="bf b bg z dw">Write a response</p></div></div><div class="cz bp ab cq wf wg"><div class="ab cq fm"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6&amp;source=---post_responses--9f8c3b98dee6---------------------respond_sidebar------------------"><div class="wp l"><p class="bf b bg z dw">What are your thoughts?</p></div></a></span><div class="cr wh dw ab wi vj wj"><span class="bf b bg z dw"><div class="ab"><div><div class="bm" aria-hidden="false" aria-describedby="40" aria-labelledby="40"><span class="wq wr ws wt bp lg cd wu wv ww"><svg width="21" height="21"><path fill-rule="evenodd" d="M10.308 17.993h-5.92l.11-.894.783-.12c.56-.11.79-.224.79-.448V5.37c0-.225-.113-.336-.902-.448H4.5l-.114-.894h6.255c4.02 0 5.58 1.23 5.58 3.13 0 1.896-1.78 3.125-3.79 3.463v.11c2.69.34 4.25 1.56 4.25 3.57 0 2.35-2.01 3.69-6.37 3.69l.02.01h-.02zm-.335-12.96H8.967V10.5h1.23c1.788 0 2.79-1.23 2.79-2.683 0-1.685-1.004-2.803-3.006-2.803v.02zm-.223 6.36h-.783v5.588l1.225.23h.22c1.67 0 3.01-1.004 3.01-2.792 0-2.122-1.566-3.016-3.69-3.016h.018z"></path></svg></span></div></div><div><div class="bm" aria-hidden="false" aria-describedby="41" aria-labelledby="41"><span class="wq wr ws wt bp lg cd wu wv ww"><svg width="21" height="21"><path fill-rule="evenodd" d="M9.847 18.04c-.533 0-2.027-.64-1.92-.853l2.027-7.68-.64-.214-1.387 1.494-.427-.427c.534-1.173 1.707-2.667 2.774-2.667.533 0 2.24.534 2.133.854l-2.133 7.786.533.214 1.6-1.067.427.427c-.64 1.066-1.92 2.133-2.987 2.133m2.347-11.733c-.96 0-1.387-.64-1.387-1.387 0-1.067.747-1.92 1.493-1.92.854 0 1.387.64 1.387 1.493-.107 1.067-.747 1.814-1.493 1.814"></path></svg></span></div></div></div></span><div class="wk tl ab wi vj wj"><div class="wl"><button class="bf b dx z bk wx wy wz xa lf lb tr ex ey ez xb xc xd fc fd fe ff bm fg fh" data-testid="CancelResponseButton">Cancel</button></div><button class="bf b dx z tm wx tn to tp tq tr ex ey ts tt tu fc fd fe ff bm fg fh" disabled="disabled" data-testid="ResponseRespondButton">Respond</button></div></div></div></div><div class="ab wi vj wj"><span role="checkbox" aria-checked="false" tabindex="0" class="wm"><label class="ab q"><div class="sa xv xw ab xx cb fm"><input class="xe xf xg fv vj xh xi xj xk xl xm xn" type="checkbox" disabled="disabled"><span class="q xo xp fd fe xq ff tm xr ab tn wd cd xs xt" data-checkbox="true"><svg xmlns="http://www.w3.org/2000/svg" width="11" height="11" viewBox="0 0 11 11" class="tn xu"><path d="m0 6.313 3.704 3.705.904.904.66-1.095 5.296-8.795L8.85 0 3.554 8.795l1.563-.191-3.704-3.705z"></path></svg></span></div><div class="l"><p class="bf b dx z dw">Also publish to my profile</p></div></label></span></div></div></div></div></div></div></div></div></div><div class="uu uv uw ux uy l bx"><div class="ab cd"><div class="ck bh gc gd ge gf"><div class="xz ya do dp dq uj l"><h2 class="bf ub ny oa ob oc oe of og oi oj ok om on oo oq or bk">More from David Liang</h2></div><div class="xx ab kd iu yb yc yd ye yf yg yh yi yj yk yl ym yn yo yp"><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/@davidlfliang/intro-python-algorithms-traveling-salesman-problem-ffa61f0bd47b" tabindex="0"><div class="abb"><div aria-label="Intro — Python Algorithms: Traveling Salesman Problem"><div class="abd abe abf abg abh"><img alt="Intro — Python Algorithms: Traveling Salesman Problem" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_4qG9OKfN5h5oFRuaSYOoWg.jpg" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="111" aria-labelledby="111"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---author_recirc--9f8c3b98dee6----0---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div class="l fm"><img alt="David Liang" class="l ff by abu abv cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_KRQjDf-7XCRVNlpsS3QpOg_003.jpg" width="20" height="20" loading="lazy"><div class="fu by l abu abv fv n ay fw"></div></div></a></div></div></div><div><div class="l" aria-hidden="false" aria-describedby="112" aria-labelledby="112"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---author_recirc--9f8c3b98dee6----0---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">David Liang</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/@davidlfliang/intro-python-algorithms-traveling-salesman-problem-ffa61f0bd47b?source=post_page---author_recirc--9f8c3b98dee6----0---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div title=""><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">Intro — Python Algorithms: Traveling Salesman Problem</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">The
 Traveling Salesman Problem (TSP) is a classic problem in computer 
science and operations research. It is an optimization problem that…</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><span>Jul 17, 2024</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/@davidlfliang/intro-python-algorithms-traveling-salesman-problem-ffa61f0bd47b?source=post_page---author_recirc--9f8c3b98dee6----0---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div><div class="ab" aria-hidden="false" aria-describedby="267" aria-labelledby="267"><div class="ab q add"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>7</span></div></div></div></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="113" aria-labelledby="113"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fffa61f0bd47b&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-python-algorithms-traveling-salesman-problem-ffa61f0bd47b&amp;source=---author_recirc--9f8c3b98dee6----0-----------------bookmark_preview----81f9a978_029b_4832_bf37_80325c038144--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="ul bh uz ld"></div></div></div></div></div></div></div></div></article></div></div><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/@davidlfliang/intro-python-algorithms-eight-queens-problem-fdcc5cf384d5" tabindex="0"><div class="abb"><div aria-label="Intro — Python Algorithms: Eight Queens Problem"><div class="abd abe abf abg abh"><img alt="Intro — Python Algorithms: Eight Queens Problem" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_x7f4XokdhaR8wmeWnqeXxw.png" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="114" aria-labelledby="114"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---author_recirc--9f8c3b98dee6----1---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div class="l fm"><img alt="David Liang" class="l ff by abu abv cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_KRQjDf-7XCRVNlpsS3QpOg_003.jpg" width="20" height="20" loading="lazy"><div class="fu by l abu abv fv n ay fw"></div></div></a></div></div></div><div><div class="l" aria-hidden="false" aria-describedby="115" aria-labelledby="115"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---author_recirc--9f8c3b98dee6----1---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">David Liang</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/@davidlfliang/intro-python-algorithms-eight-queens-problem-fdcc5cf384d5?source=post_page---author_recirc--9f8c3b98dee6----1---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div title=""><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">Intro — Python Algorithms: Eight Queens Problem</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">Problem Statement</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><span>Sep 2, 2024</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/@davidlfliang/intro-python-algorithms-eight-queens-problem-fdcc5cf384d5?source=post_page---author_recirc--9f8c3b98dee6----1---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div><div class="ab" aria-hidden="false" aria-describedby="268" aria-labelledby="268"><div class="ab q add"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>38</span></div></div></div><div><div class="ab" aria-hidden="false" aria-describedby="116" aria-labelledby="116"><div class="ab q add"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" viewBox="0 0 16 16"><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>1</span></div></div></div></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="117" aria-labelledby="117"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffdcc5cf384d5&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-python-algorithms-eight-queens-problem-fdcc5cf384d5&amp;source=---author_recirc--9f8c3b98dee6----1-----------------bookmark_preview----81f9a978_029b_4832_bf37_80325c038144--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="ul bh uz ld"></div></div></div></div></div></div></div></div></article></div></div><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/@davidlfliang/intro-ml-with-python-part-2-of-4-binary-classification-70fa38830157" tabindex="0"><div class="abb"><div aria-label="Intro — ML with Python: Part 2 of 4 — Binary Classification"><div class="abd abe abf abg abh"><img alt="Intro — ML with Python: Part 2 of 4 — Binary Classification" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_CuHjyV9XWmtdJ-kP2DH06Q.png" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="118" aria-labelledby="118"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---author_recirc--9f8c3b98dee6----2---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div class="l fm"><img alt="David Liang" class="l ff by abu abv cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_KRQjDf-7XCRVNlpsS3QpOg_003.jpg" width="20" height="20" loading="lazy"><div class="fu by l abu abv fv n ay fw"></div></div></a></div></div></div><div><div class="l" aria-hidden="false" aria-describedby="119" aria-labelledby="119"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---author_recirc--9f8c3b98dee6----2---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">David Liang</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/@davidlfliang/intro-ml-with-python-part-2-of-4-binary-classification-70fa38830157?source=post_page---author_recirc--9f8c3b98dee6----2---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div title=""><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">Intro — ML with Python: Part 2 of 4 — Binary Classification</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">Binary
 classification is a type of machine learning task where the goal is to 
categorize data into one of two distinct types. This…</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><span>Aug 23, 2024</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/@davidlfliang/intro-ml-with-python-part-2-of-4-binary-classification-70fa38830157?source=post_page---author_recirc--9f8c3b98dee6----2---------------------81f9a978_029b_4832_bf37_80325c038144--------------"></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="120" aria-labelledby="120"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70fa38830157&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-ml-with-python-part-2-of-4-binary-classification-70fa38830157&amp;source=---author_recirc--9f8c3b98dee6----2-----------------bookmark_preview----81f9a978_029b_4832_bf37_80325c038144--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="ul bh uz ld"></div></div></div></div></div></div></div></div></article></div></div><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/@davidlfliang/intro-python-algorithms-knights-tour-problem-ab0a27a5728c" tabindex="0"><div class="abb"><div aria-label="Intro — Python Algorithms: Knight’s Tour Problem"><div class="abd abe abf abg abh"><img alt="Intro — Python Algorithms: Knight’s Tour Problem" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_WlcOIafrSkyafXZfhYDqlA.jpg" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="121" aria-labelledby="121"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---author_recirc--9f8c3b98dee6----3---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div class="l fm"><img alt="David Liang" class="l ff by abu abv cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_KRQjDf-7XCRVNlpsS3QpOg_003.jpg" width="20" height="20" loading="lazy"><div class="fu by l abu abv fv n ay fw"></div></div></a></div></div></div><div><div class="l" aria-hidden="false" aria-describedby="122" aria-labelledby="122"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---author_recirc--9f8c3b98dee6----3---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">David Liang</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/@davidlfliang/intro-python-algorithms-knights-tour-problem-ab0a27a5728c?source=post_page---author_recirc--9f8c3b98dee6----3---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div title=""><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">Intro — Python Algorithms: Knight’s Tour Problem</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">Introduction</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><span>Aug 14, 2024</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/@davidlfliang/intro-python-algorithms-knights-tour-problem-ab0a27a5728c?source=post_page---author_recirc--9f8c3b98dee6----3---------------------81f9a978_029b_4832_bf37_80325c038144--------------"><div><div class="ab" aria-hidden="false" aria-describedby="270" aria-labelledby="270"><div class="ab q add"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>6</span></div></div></div></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="123" aria-labelledby="123"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fab0a27a5728c&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40davidlfliang%2Fintro-python-algorithms-knights-tour-problem-ab0a27a5728c&amp;source=---author_recirc--9f8c3b98dee6----3-----------------bookmark_preview----81f9a978_029b_4832_bf37_80325c038144--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="ul bh uz dm dn ade adf adg"></div><div class="ab is it sx sw sv"><a class="bf b bg z bk sb wy wz xa lf lb tr ex ey ez xb xc xd fc adh adi adj adk adl fd fe ff bm fg fh" rel="noopener follow" href="https://medium.com/@davidlfliang?source=post_page---author_recirc--9f8c3b98dee6---------------------------------------"><div class="l fh">See all from David Liang</div></a></div></div></div><div class="ul bh uz adm adn ado adp adq"></div><div class="ab cd"><div class="ck bh gc gd ge gf"><div class="adr ads l"><h2 class="bf ub ny oa ob oc oe of og oi oj ok om on oo oq or bk">Recommended from Medium</h2><div class="pw px py pz qa l"><div class="xx ab kd iu yb yc yd ye yf yg yh yi yj yk yl ym yn yo yp"><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/@lmpo/mastering-llms-a-guide-to-decoding-algorithms-c90a48fd167b" tabindex="0"><div class="abb"><div aria-label="Understanding LLM Decoding Strategies"><div class="abd abe abf abg abh"><img alt="Understanding LLM Decoding Strategies" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_QLA1jwTY0HBBpLBWfw_QaQ.png" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="124" aria-labelledby="124"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@lmpo?source=post_page---read_next_recirc--9f8c3b98dee6----0---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div class="l fm"><img alt="LM Po" class="l ff by abu abv cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_8biNIOdTZO6v4MDdtPmm2Q.png" width="20" height="20" loading="lazy"><div class="fu by l abu abv fv n ay fw"></div></div></a></div></div></div><div><div class="l" aria-hidden="false" aria-describedby="125" aria-labelledby="125"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@lmpo?source=post_page---read_next_recirc--9f8c3b98dee6----0---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">LM Po</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/@lmpo/mastering-llms-a-guide-to-decoding-algorithms-c90a48fd167b?source=post_page---read_next_recirc--9f8c3b98dee6----0---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div title=""><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">Understanding LLM Decoding Strategies</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">If you’re not a Medium subscriber, click here to read the full article.</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><div class="sk ab"><div class="bm" aria-hidden="false" aria-describedby="126" aria-labelledby="126"><button class="l ay ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="127" aria-labelledby="127"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Oct 25, 2024</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/@lmpo/mastering-llms-a-guide-to-decoding-algorithms-c90a48fd167b?source=post_page---read_next_recirc--9f8c3b98dee6----0---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div><div class="ab" aria-hidden="false" aria-describedby="271" aria-labelledby="271"><div class="ab q add"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>86</span></div></div></div></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="128" aria-labelledby="128"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc90a48fd167b&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40lmpo%2Fmastering-llms-a-guide-to-decoding-algorithms-c90a48fd167b&amp;source=---read_next_recirc--9f8c3b98dee6----0-----------------bookmark_preview----d323442d_a245_4b08_b192_83f591cd3936--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="ul bh uz ld"></div></div></div></div></div></div></div></div></article></div></div><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/python-in-plain-english/bert-fine-tuning-a-pre-trained-model-for-text-classification-14ffc211b51e" tabindex="0"><div class="abb"><div aria-label="BERT: Fine-tuning a Pre-trained Model for Text Classification"><div class="abd abe abf abg abh"><img alt="BERT: Fine-tuning a Pre-trained Model for Text Classification" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/0_upX3ZOHmtttEEZGp.jpg" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="129" aria-labelledby="129"><a href="https://medium.com/python-in-plain-english?source=post_page---read_next_recirc--9f8c3b98dee6----1---------------------d323442d_a245_4b08_b192_83f591cd3936--------------" rel="noopener follow"><div class="fm"><img alt="Python in Plain English" class="cz xq l abv abu" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_VA3oGfprJgj5fRsTjXp6fA@2x.png" width="20" height="20" loading="lazy"><div class="xq l abu abv fv n fu fw"></div></div></a></div></div></div><div class="ua l"><p class="bf b dx z dw">In</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="130" aria-labelledby="130"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" href="https://medium.com/python-in-plain-english?source=post_page---read_next_recirc--9f8c3b98dee6----1---------------------d323442d_a245_4b08_b192_83f591cd3936--------------" rel="noopener follow"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">Python in Plain English</p></a></div></div></div><div class="adt l"><p class="bf b dx z dw">by</p></div><div><div class="l" aria-hidden="false" aria-describedby="131" aria-labelledby="131"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@mohamad.razzi.my?source=post_page---read_next_recirc--9f8c3b98dee6----1---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">Mohamad Mahmood</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/python-in-plain-english/bert-fine-tuning-a-pre-trained-model-for-text-classification-14ffc211b51e?source=post_page---read_next_recirc--9f8c3b98dee6----1---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div title=""><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">BERT: Fine-tuning a Pre-trained Model for Text Classification</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">This
 article involves fine-tuning a pre-trained DistilBERT model for text 
classification, where the task is to classify text samples into…</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><div class="sk ab"><div class="bm" aria-hidden="false" aria-describedby="132" aria-labelledby="132"><button class="l ay ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="133" aria-labelledby="133"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Jan 3</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/python-in-plain-english/bert-fine-tuning-a-pre-trained-model-for-text-classification-14ffc211b51e?source=post_page---read_next_recirc--9f8c3b98dee6----1---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div><div class="ab" aria-hidden="false" aria-describedby="272" aria-labelledby="272"><div class="ab q add"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>15</span></div></div></div></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="134" aria-labelledby="134"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F14ffc211b51e&amp;operation=register&amp;redirect=https%3A%2F%2Fpython.plainenglish.io%2Fbert-fine-tuning-a-pre-trained-model-for-text-classification-14ffc211b51e&amp;source=---read_next_recirc--9f8c3b98dee6----1-----------------bookmark_preview----d323442d_a245_4b08_b192_83f591cd3936--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div></div><div class="xx ab kd iu yb yc yd ye yf yg yh yi yj yk yl ym yn yo yp"><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/about-ai/understanding-embedding-models-in-the-context-of-large-language-models-02da706ee9b3" tabindex="0"><div class="abb"><div aria-label="Understanding Embedding Models in the Context of Large Language Models"><div class="abd abe abf abg abh"><img alt="Understanding Embedding Models in the Context of Large Language Models" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_jmOTjKQ9HKVdbov_-UqfSQ.png" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="135" aria-labelledby="135"><a href="https://medium.com/about-ai?source=post_page---read_next_recirc--9f8c3b98dee6----0---------------------d323442d_a245_4b08_b192_83f591cd3936--------------" rel="noopener follow"><div class="fm"><img alt="about ai" class="cz xq l abv abu" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_FFy6UERlSva-YEhYCLwD0Q.png" width="20" height="20" loading="lazy"><div class="xq l abu abv fv n fu fw"></div></div></a></div></div></div><div class="ua l"><p class="bf b dx z dw">In</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="136" aria-labelledby="136"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" href="https://medium.com/about-ai?source=post_page---read_next_recirc--9f8c3b98dee6----0---------------------d323442d_a245_4b08_b192_83f591cd3936--------------" rel="noopener follow"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">about ai</p></a></div></div></div><div class="adt l"><p class="bf b dx z dw">by</p></div><div><div class="l" aria-hidden="false" aria-describedby="137" aria-labelledby="137"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@viajesubmarino?source=post_page---read_next_recirc--9f8c3b98dee6----0---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">Edgar</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/about-ai/understanding-embedding-models-in-the-context-of-large-language-models-02da706ee9b3?source=post_page---read_next_recirc--9f8c3b98dee6----0---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div title=""><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">Understanding Embedding Models in the Context of Large Language Models</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">Large
 Language Models (LLMs) like GPT, BERT, and similar architectures have 
revolutionized the field of natural language processing (NLP)…</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><div class="sk ab"><div class="bm" aria-hidden="false" aria-describedby="138" aria-labelledby="138"><button class="l ay ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="139" aria-labelledby="139"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Jan 28</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/about-ai/understanding-embedding-models-in-the-context-of-large-language-models-02da706ee9b3?source=post_page---read_next_recirc--9f8c3b98dee6----0---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="140" aria-labelledby="140"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F02da706ee9b3&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fabout-ai%2Funderstanding-embedding-models-in-the-context-of-large-language-models-02da706ee9b3&amp;source=---read_next_recirc--9f8c3b98dee6----0-----------------bookmark_preview----d323442d_a245_4b08_b192_83f591cd3936--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="ul bh uz ld"></div></div></div></div></div></div></div></div></article></div></div><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/@dkaarthick/choosing-the-best-approach-for-multi-class-text-classification-a-comprehensive-guide-a2159aaeb20b" tabindex="0"><div class="abb"><div aria-label="Choosing the Best Approach for Multi-Class Text Classification: A Comprehensive Guide"><div class="abd abe abf abg abh"><img alt="Choosing the Best Approach for Multi-Class Text Classification: A Comprehensive Guide" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_spkhN7BSClpchZzBxRD9iA.jpg" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="141" aria-labelledby="141"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@dkaarthick?source=post_page---read_next_recirc--9f8c3b98dee6----1---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div class="l fm"><img alt="Karthikeyan Dhanakotti" class="l ff by abu abv cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_FzplnteHXxPmaLwIXnOoFw.jpg" width="20" height="20" loading="lazy"><div class="fu by l abu abv fv n ay fw"></div></div></a></div></div></div><div><div class="l" aria-hidden="false" aria-describedby="142" aria-labelledby="142"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@dkaarthick?source=post_page---read_next_recirc--9f8c3b98dee6----1---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">Karthikeyan Dhanakotti</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/@dkaarthick/choosing-the-best-approach-for-multi-class-text-classification-a-comprehensive-guide-a2159aaeb20b?source=post_page---read_next_recirc--9f8c3b98dee6----1---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div title="Choosing the Best Approach for Multi-Class Text Classification: A Comprehensive Guide"><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">Choosing the Best Approach for Multi-Class Text Classification: A Comprehensive Guide</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">Text
 classification is one of the foundational tasks in natural language 
processing (NLP), widely used for spam detection, sentiment…</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><div class="sk ab"><div class="bm" aria-hidden="false" aria-describedby="143" aria-labelledby="143"><button class="l ay ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="144" aria-labelledby="144"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Jan 9</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/@dkaarthick/choosing-the-best-approach-for-multi-class-text-classification-a-comprehensive-guide-a2159aaeb20b?source=post_page---read_next_recirc--9f8c3b98dee6----1---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div><div class="ab" aria-hidden="false" aria-describedby="273" aria-labelledby="273"><div class="ab q add"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>1</span></div></div></div></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="145" aria-labelledby="145"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa2159aaeb20b&amp;operation=register&amp;redirect=https%3A%2F%2Fdkaarthick.medium.com%2Fchoosing-the-best-approach-for-multi-class-text-classification-a-comprehensive-guide-a2159aaeb20b&amp;source=---read_next_recirc--9f8c3b98dee6----1-----------------bookmark_preview----d323442d_a245_4b08_b192_83f591cd3936--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="ul bh uz ld"></div></div></div></div></div></div></div></div></article></div></div><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/@dhirajkumarblog/fine-tuning-large-language-models-bert-roberta-sbert-a457182ba8bf" tabindex="0"><div class="abb"><div aria-label="Fine-Tuning Large Language Models (BERT, RoBERTa, SBERT)"><div class="abd abe abf abg abh"><img alt="Fine-Tuning Large Language Models (BERT, RoBERTa, SBERT)" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1_yuVzMhCJyDENbyhwAsrkwA.png" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="146" aria-labelledby="146"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@dhirajkumarblog?source=post_page---read_next_recirc--9f8c3b98dee6----2---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div class="l fm"><img alt="Dhiraj K" class="l ff by abu abv cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/2_BL_TY3gMpMgX_RivIC230A.jpg" width="20" height="20" loading="lazy"><div class="fu by l abu abv fv n ay fw"></div></div></a></div></div></div><div><div class="l" aria-hidden="false" aria-describedby="147" aria-labelledby="147"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@dhirajkumarblog?source=post_page---read_next_recirc--9f8c3b98dee6----2---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">Dhiraj K</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/@dhirajkumarblog/fine-tuning-large-language-models-bert-roberta-sbert-a457182ba8bf?source=post_page---read_next_recirc--9f8c3b98dee6----2---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div title=""><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">Fine-Tuning Large Language Models (BERT, RoBERTa, SBERT)</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">Introduction: From Academia to Business Value</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><div class="sk ab"><div class="bm" aria-hidden="false" aria-describedby="148" aria-labelledby="148"><button class="l ay ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="149" aria-labelledby="149"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Oct 30, 2024</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/@dhirajkumarblog/fine-tuning-large-language-models-bert-roberta-sbert-a457182ba8bf?source=post_page---read_next_recirc--9f8c3b98dee6----2---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div><div class="ab" aria-hidden="false" aria-describedby="274" aria-labelledby="274"><div class="ab q add"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>3</span></div></div></div></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="150" aria-labelledby="150"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa457182ba8bf&amp;operation=register&amp;redirect=https%3A%2F%2Fdhirajkumarblog.medium.com%2Ffine-tuning-large-language-models-bert-roberta-sbert-a457182ba8bf&amp;source=---read_next_recirc--9f8c3b98dee6----2-----------------bookmark_preview----d323442d_a245_4b08_b192_83f591cd3936--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="ul bh uz ld"></div></div></div></div></div></div></div></div></article></div></div><div class="yq yr ys tz yt yu yv ty yw yx yy yz za zb zc zd ze zf zg zh zi"><div class="zj zk zl zm zn dy l"><article class="dy" data-testid="post-preview"><div class="dy sk l"><div class="bh dy"><div class="dy l"><div class="fm dy zo zp zq zr zs zt zu zv zw zx zy zz aba" role="link" data-href="https://medium.com/@whyamit101/how-to-fine-tune-embedding-models-for-rag-retrieval-augmented-generation-7c5bf08b3c54" tabindex="0"><div class="abb"><div aria-label="How to Fine-Tune Embedding Models for RAG (Retrieval-Augmented Generation)?"><div class="abd abe abf abg abh"><img alt="How to Fine-Tune Embedding Models for RAG (Retrieval-Augmented Generation)?" class="bh abi abj abk bx" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/0_z2lFOAxVtBKtZ-Bf.png" loading="lazy"></div></div></div><div class="abc ab cd cq"><div class="ab cq wd bh abl abm abn abo"><div class="abp abq abr abs abt ab q"><div class="sa l"><div><div class="l" aria-hidden="false" aria-describedby="151" aria-labelledby="151"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@whyamit101?source=post_page---read_next_recirc--9f8c3b98dee6----3---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div class="l fm"><img alt="why amit" class="l ff by abu abv cz" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/0_Kg7r8ds7B7oda6ZC.png" width="20" height="20" loading="lazy"><div class="fu by l abu abv fv n ay fw"></div></div></a></div></div></div><div><div class="l" aria-hidden="false" aria-describedby="152" aria-labelledby="152"><a class="ag ah ai aj ak al am an ao ap aq ar as io ab q" rel="noopener follow" href="https://medium.com/@whyamit101?source=post_page---read_next_recirc--9f8c3b98dee6----3---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><p class="bf b dx z rj abw rl rm abx ro aby rp bk">why amit</p></a></div></div></div><div class="abz l aca acb acc acd ace gq"><div class="acf acg ach aci acj ack acl acm"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/@whyamit101/how-to-fine-tune-embedding-models-for-rag-retrieval-augmented-generation-7c5bf08b3c54?source=post_page---read_next_recirc--9f8c3b98dee6----3---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div title="How to Fine-Tune Embedding Models for RAG (Retrieval-Augmented Generation)?"><h2 class="bf gy ny oa acn aco ob oc oe acp acq of ni pe acr acs pf nm ph act acu pi nq pk acv acw pl rj rl rm ro rp bk">How to Fine-Tune Embedding Models for RAG (Retrieval-Augmented Generation)?</h2></div><div class="acx l"><h3 class="bf b im z rj rk rl rm rn ro rp dw">A Step-by-Step Guide With Code</h3></div></a></div></div><span class="bf b dx z dw"><div class="if ab cr ae"><div class="ab q af"><span>Dec 18, 2024</span><div class=""><div class="fm acy dj ab q"><div class="fv vj acz ab q af"><div class="fi dj dl l cz"></div></div><a class="fv kz acz ab q af" tabindex="-1" rel="noopener follow" href="https://medium.com/@whyamit101/how-to-fine-tune-embedding-models-for-rag-retrieval-augmented-generation-7c5bf08b3c54?source=post_page---read_next_recirc--9f8c3b98dee6----3---------------------d323442d_a245_4b08_b192_83f591cd3936--------------"><div><div class="ab" aria-hidden="false" aria-describedby="275" aria-labelledby="275"><div class="ab q add"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>2</span></div></div></div></a></div></div></div><div class="ab q ada adb"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="153" aria-labelledby="153"><span><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7c5bf08b3c54&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40whyamit101%2Fhow-to-fine-tune-embedding-models-for-rag-retrieval-augmented-generation-7c5bf08b3c54&amp;source=---read_next_recirc--9f8c3b98dee6----3-----------------bookmark_preview----d323442d_a245_4b08_b192_83f591cd3936--------------"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dw lf adc" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="ul bh uz dm dn ade adf adg"></div><a class="bf b bg z bk sb wy wz xa lf lb tr ex ey ez xb xc xd fc adh adi adj adk adl fd fe ff bm fg fh" rel="noopener follow" href="https://medium.com/?source=post_page---read_next_recirc--9f8c3b98dee6---------------------------------------"><div class="l fh">See more recommendations</div></a></div></div></div><div class="h k j"><div class="ul bh uz va"></div><div class="ab cd"><div class="ck bh gc gd ge gf"><div class="vb ab kd iu"><div class="vc vd l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" href="https://help.medium.com/hc/en-us?source=post_page-----9f8c3b98dee6---------------------------------------" rel="noopener follow"><p class="bf b dx z dw">Help</p></a></div><div class="vc vd l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" href="https://medium.statuspage.io/?source=post_page-----9f8c3b98dee6---------------------------------------" rel="noopener follow"><p class="bf b dx z dw">Status</p></a></div><div class="vc vd l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/about?autoplay=1&amp;source=post_page-----9f8c3b98dee6---------------------------------------"><p class="bf b dx z dw">About</p></a></div><div class="vc vd l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----9f8c3b98dee6---------------------------------------"><p class="bf b dx z dw">Careers</p></a></div><div class="vc vd l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" href="mailto:pressinquiries@medium.com" rel="noopener follow"><p class="bf b dx z dw">Press</p></a></div><div class="vc vd l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" href="https://blog.medium.com/?source=post_page-----9f8c3b98dee6---------------------------------------" rel="noopener follow"><p class="bf b dx z dw">Blog</p></a></div><div class="vc vd l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9f8c3b98dee6---------------------------------------" rel="noopener follow"><p class="bf b dx z dw">Privacy</p></a></div><div class="vc vd l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----9f8c3b98dee6---------------------------------------" rel="noopener follow"><p class="bf b dx z dw">Rules</p></a></div><div class="vc vd l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9f8c3b98dee6---------------------------------------" rel="noopener follow"><p class="bf b dx z dw">Terms</p></a></div><div class="vc l"><a class="ag ah ai aj ak al am an ao ap aq ar as at au" href="https://speechify.com/medium?source=post_page-----9f8c3b98dee6---------------------------------------" rel="noopener follow"><p class="bf b dx z dw">Text to speech</p></a></div></div></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20250404-165556-7f2f10e5a9"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-9f8c3b98dee6","user-edc72cb1fd52"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"pubFeaturingPostPageLabelEnabled":false,"storySubscribeCopyEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"DEFAULT","explicit":false},"viewerIsBot":false},"debug":{"requestId":"2eea9d07-6b70-4073-bd39-91b77e05814c","requestTag":"","hybridDevServices":[],"originalSpanCarrier":{"traceparent":"00-f0af1dc5e62a94502ca557875dd61042-0563eba424fd83f7-01"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmedium.com\u002F@davidlfliang\u002Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6","host":"medium.com","hostname":"medium.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"partnerProgram":{"selectedCountryCode":null},"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20250404-165556-7f2f10e5a9","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20250404-165556-7f2f10e5a9","commit":"7f2f10e5a99ebccbab159c0276ceee3b9a78c1de"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"7*V1_7XP4snlmqrc_0Njontw.png","height":110,"width":500},"postLogo":{"imageId":"bd978bb536350a710e8efb012513429cabdc4c28700604261aeda246d0f980b7","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"medium.com\"})":null,"postResult({\"id\":\"9f8c3b98dee6\"})":{"__ref":"Post:9f8c3b98dee6"}},"LinkedAccounts:edc72cb1fd52":{"__typename":"LinkedAccounts","mastodon":null,"id":"edc72cb1fd52"},"Membership:e442610945de":{"__typename":"Membership","tier":"MEMBER","id":"e442610945de"},"User:edc72cb1fd52":{"__typename":"User","id":"edc72cb1fd52","linkedAccounts":{"__ref":"LinkedAccounts:edc72cb1fd52"},"isSuspended":false,"name":"David Liang","imageId":"1*KRQjDf-7XCRVNlpsS3QpOg.jpeg","customDomainState":null,"hasSubdomain":false,"username":"davidlfliang","verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":103,"followingCount":9,"collectionFollowingCount":4},"bio":"Full Stack AI\u002FData Engineer - Architecting integrated solutions across full-stack development and advanced AI\u002Fdata engineering.","membership":{"__ref":"Membership:e442610945de"},"allowNotes":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:edc72cb1fd52-viewerId:lo_8e52d96f0d22"},"twitterScreenName":""},"Paragraph:c54ad4e0d3ba_0":{"__typename":"Paragraph","id":"c54ad4e0d3ba_0","name":"f55c","type":"H3","href":null,"layout":null,"metadata":null,"text":"Intro — Getting Started with Text Embeddings: Using BERT","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*7qIA2ypzDmgjpRIQX-ICmQ.jpeg":{"__typename":"ImageMetadata","id":"1*7qIA2ypzDmgjpRIQX-ICmQ.jpeg","originalHeight":1024,"originalWidth":1024,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:c54ad4e0d3ba_1":{"__typename":"Paragraph","id":"c54ad4e0d3ba_1","name":"113b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*7qIA2ypzDmgjpRIQX-ICmQ.jpeg"},"text":"The quick red fox jumps over the lazy dog.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_2":{"__typename":"Paragraph","id":"c54ad4e0d3ba_2","name":"ff36","type":"P","href":null,"layout":null,"metadata":null,"text":"Contextual embeddings have revolutionized natural language processing (NLP) by providing richer, context-aware representations of text. This guide will delve deeper into the theory behind contextual embeddings. We’ll provide a simple Python example and explain how to use BERT for sentence embeddings to perform text similarity searches.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_3":{"__typename":"Paragraph","id":"c54ad4e0d3ba_3","name":"a28e","type":"H3","href":null,"layout":null,"metadata":null,"text":"1. The Concept of Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":28,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_4":{"__typename":"Paragraph","id":"c54ad4e0d3ba_4","name":"c211","type":"P","href":null,"layout":null,"metadata":null,"text":"What is an Embedding? An embedding is a dense, continuous vector representation of discrete items, such as words or tokens. Unlike traditional methods that use high-dimensional, sparse representations (e.g., one-hot encoding), embeddings are lower-dimensional and capture semantic meaning more effectively.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_5":{"__typename":"Paragraph","id":"c54ad4e0d3ba_5","name":"0d6a","type":"P","href":null,"layout":null,"metadata":null,"text":"Why “Embedding”? The term “embedding” refers to the process of mapping discrete data (like words) into a continuous vector space. This “embedding” allows models to represent words in a way that reflects their semantic relationships and contextual usage. The term implies that words are “embedded” into a space where similar meanings are mapped closer together.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_6":{"__typename":"Paragraph","id":"c54ad4e0d3ba_6","name":"61e2","type":"P","href":null,"layout":null,"metadata":null,"text":"Embeddings enable the conversion of text into dense vectors that capture semantic meaning and context, facilitating tasks like text similarity search, classification, and language translation by providing a meaningful numerical representation of text.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_7":{"__typename":"Paragraph","id":"c54ad4e0d3ba_7","name":"ab8f","type":"H3","href":null,"layout":null,"metadata":null,"text":"2. BERT","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_8":{"__typename":"Paragraph","id":"c54ad4e0d3ba_8","name":"8198","type":"P","href":null,"layout":null,"metadata":null,"text":"BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained language model that uses bidirectional context to enhance performance on natural language processing tasks. Leveraging the Transformer architecture, it captures nuanced word meanings by considering context from both directions in a sentence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_9":{"__typename":"Paragraph","id":"c54ad4e0d3ba_9","name":"718d","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.1 Tokenization Process","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_10":{"__typename":"Paragraph","id":"c54ad4e0d3ba_10","name":"e04b","type":"P","href":null,"layout":null,"metadata":null,"text":"Tokenization is a crucial step that occurs before the BERT model itself is applied. It is part of the preprocessing pipeline for preparing input text for BERT. Here’s a breakdown of where tokenization fits into the process:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_11":{"__typename":"Paragraph","id":"c54ad4e0d3ba_11","name":"300b","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Text Preprocessing: Before any model like BERT is used, the raw text data needs to be processed and converted into a format suitable for the model. This includes tokenization.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_12":{"__typename":"Paragraph","id":"c54ad4e0d3ba_12","name":"2bf9","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Tokenization: This is the step where the input text is split into smaller units, called tokens. For BERT, tokenization involves:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_13":{"__typename":"Paragraph","id":"c54ad4e0d3ba_13","name":"e108","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Splitting Text: Breaking down sentences into words or subword units.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_14":{"__typename":"Paragraph","id":"c54ad4e0d3ba_14","name":"19f4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Mapping Tokens to IDs: Converting tokens into numerical IDs based on BERT’s vocabulary.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_15":{"__typename":"Paragraph","id":"c54ad4e0d3ba_15","name":"93b8","type":"P","href":null,"layout":null,"metadata":null,"text":"3. Input Formatting: After tokenization, the tokens are converted into input formats that BERT can process. This involves:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_16":{"__typename":"Paragraph","id":"c54ad4e0d3ba_16","name":"056a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Creating Input Tensors: For BERT, this includes input IDs, attention masks, and token type IDs.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_17":{"__typename":"Paragraph","id":"c54ad4e0d3ba_17","name":"e4ec","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.2 Tokenization Process — Code Example","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_18":{"__typename":"Paragraph","id":"c54ad4e0d3ba_18","name":"8141","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s use the most famous pangram “The quick brown fox jumps over the lazy dog.” as our test input and write a simple Python code that demonstrates how to use the transformers library to tokenize text using a pre-trained BERT model.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":33,"end":80,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_19":{"__typename":"Paragraph","id":"c54ad4e0d3ba_19","name":"4e55","type":"P","href":null,"layout":null,"metadata":null,"text":"Install Required Packages:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_20":{"__typename":"Paragraph","id":"c54ad4e0d3ba_20","name":"b50f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"pip install transformers torch","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_21":{"__typename":"Paragraph","id":"c54ad4e0d3ba_21","name":"1d5f","type":"P","href":null,"layout":null,"metadata":null,"text":"Here’s a brief overview of each package:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_22":{"__typename":"Paragraph","id":"c54ad4e0d3ba_22","name":"aabd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"transformers: This is the Hugging Face transformers library, it provides pre-trained models and tools for various natural language processing (NLP) tasks, including tokenization and model inference.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":39,"end":51,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_23":{"__typename":"Paragraph","id":"c54ad4e0d3ba_23","name":"26a7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"torch: This is the core library for PyTorch, a popular deep learning framework used for building and training neural networks.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_24":{"__typename":"Paragraph","id":"c54ad4e0d3ba_24","name":"6ed8","type":"P","href":null,"layout":null,"metadata":null,"text":"Sample Code:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_25":{"__typename":"Paragraph","id":"c54ad4e0d3ba_25","name":"380b","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from transformers import BertTokenizer\n\n# Load BERT tokenizer\nbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Example text\ntext = \"The quick brown fox jumps over the lazy dog.\"\n\n# Tokenize with BERT tokenizer\nbert_inputs = bert_tokenizer(text, return_tensors='pt')\n\nprint(\"Token IDs:\", bert_inputs['input_ids'])\n\nattention_mask = bert_inputs['attention_mask']\nprint(\"Attention Mask:\", attention_mask)\n\ntoken_type_ids = bert_inputs['token_type_ids']\nprint(\"Token Type IDs:\", token_type_ids)\n\n# Print the tokens themselves to understand the splits\ntokens = bert_tokenizer.convert_ids_to_tokens(bert_inputs['input_ids'][0])\nprint(\"Tokens:\", tokens)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_26":{"__typename":"Paragraph","id":"c54ad4e0d3ba_26","name":"7fb5","type":"P","href":null,"layout":null,"metadata":null,"text":"Output:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_27":{"__typename":"Paragraph","id":"c54ad4e0d3ba_27","name":"d09a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Token IDs: tensor([[  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,\n          1012,   102]])\nAttention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\nToken Type IDs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\nTokens: ['[CLS]', 'the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.', '[SEP]']","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_28":{"__typename":"Paragraph","id":"c54ad4e0d3ba_28","name":"88f1","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.3 Tokenization Process — Code Explanation:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_29":{"__typename":"Paragraph","id":"c54ad4e0d3ba_29","name":"0758","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BertTokenizer.from_pretrained('bert-base-uncased'): specifies the BERT base model with lowercase tokens.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_30":{"__typename":"Paragraph","id":"c54ad4e0d3ba_30","name":"d630","type":"ULI","href":null,"layout":null,"metadata":null,"text":"bert_tokenizer(text, return_tensors='pt'): Tokenizes the input text and returns tensors formatted for PyTorch ('pt').","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":111,"end":115,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_31":{"__typename":"Paragraph","id":"c54ad4e0d3ba_31","name":"d45b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"bert_inputs['input_ids']: Contains the numerical IDs corresponding to each token in the input text.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_32":{"__typename":"Paragraph","id":"c54ad4e0d3ba_32","name":"6da3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"bert_inputs['attention_mask']: Indicates which tokens should be attended to (1) and which should be ignored (0).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":29,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":29,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_33":{"__typename":"Paragraph","id":"c54ad4e0d3ba_33","name":"cce2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"bert_inputs['token_type_ids']: Used to distinguish between different segments of text (e.g., in question-answering tasks). For a single sentence, this is typically all zeros.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":29,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":29,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_34":{"__typename":"Paragraph","id":"c54ad4e0d3ba_34","name":"bf11","type":"ULI","href":null,"layout":null,"metadata":null,"text":"bert_tokenizer.convert_ids_to_tokens(bert_inputs['input_ids'][0]): Converts token IDs back into human-readable tokens to visualize the tokenization process.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":65,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":65,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_35":{"__typename":"Paragraph","id":"c54ad4e0d3ba_35","name":"95b6","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.4 Embedding Generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_36":{"__typename":"Paragraph","id":"c54ad4e0d3ba_36","name":"b9dd","type":"P","href":null,"layout":null,"metadata":null,"text":"Embedding generation occurs after tokenization, where tokenized inputs are processed by the model to produce dense vector representations capturing contextual meaning.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_37":{"__typename":"Paragraph","id":"c54ad4e0d3ba_37","name":"5b8c","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.5 Embedding Generation — Code Example","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_38":{"__typename":"Paragraph","id":"c54ad4e0d3ba_38","name":"8e97","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from transformers import BertTokenizer, BertModel\nimport torch\n\n# Load pre-trained model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\n# Define the text\ntext = \"The quick brown fox jumps over the lazy dog.\"\n\n# Tokenize the text\ninputs = tokenizer(text, return_tensors='pt')\n\n# Obtain the embeddings\nwith torch.no_grad():\n    outputs = model(**inputs)\n\n# Extract the last hidden state (embeddings)\nlast_hidden_states = outputs.last_hidden_state\n\n# Print the dimensions of the embeddings\nprint(\"Shape of the last hidden state (embeddings):\", last_hidden_states.shape)\n\n# Print embeddings for each token along with their vector dimension\ntokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\nfor token, embedding in zip(tokens, last_hidden_states[0]):\n    print(f\"Token: {token}, Embedding Dimension: {embedding.shape}, Embedding (first 5 components): {embedding[:5]}...\")  # Display first 5 components for brevity","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_39":{"__typename":"Paragraph","id":"c54ad4e0d3ba_39","name":"0a55","type":"P","href":null,"layout":null,"metadata":null,"text":"Output:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_40":{"__typename":"Paragraph","id":"c54ad4e0d3ba_40","name":"afc4","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Shape of the last hidden state (embeddings): torch.Size([1, 12, 768])\nToken: [CLS], Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.3608,  0.2271, -0.3030, -0.1880,  0.0475])...\nToken: the, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.3276, -0.3762, -0.5044,  0.0098,  0.9037])...\nToken: quick, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.4000, -0.4212,  0.4903,  0.0033,  0.4567])...\nToken: brown, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.1209, -0.2728,  0.5550, -0.1874,  0.7759])...\nToken: fox, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.0323, -0.2305, -0.1756, -0.1121,  0.5692])...\nToken: jumps, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.2432, -0.0648,  0.3022,  0.2046,  0.7072])...\nToken: over, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.3485,  0.2208,  0.1372, -0.2754,  0.4551])...\nToken: the, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.4386, -0.4292,  0.0082,  0.0577,  0.5005])...\nToken: lazy, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([0.0259, 0.1114, 0.7189, 0.1787, 0.0898])...\nToken: dog, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([0.6786, 0.0645, 0.2290, 0.3369, 0.0735])...\nToken: ., Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.1088, -0.1644, -0.2961, -0.1514,  0.1527])...\nToken: [SEP], Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.7099,  0.4367, -0.4851,  0.1776,  0.1749])...","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_41":{"__typename":"Paragraph","id":"c54ad4e0d3ba_41","name":"edf8","type":"H4","href":null,"layout":null,"metadata":null,"text":"Code Walkthrough","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_42":{"__typename":"Paragraph","id":"c54ad4e0d3ba_42","name":"c6f8","type":"P","href":null,"layout":null,"metadata":null,"text":"2.5.1 Import Libraries:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_43":{"__typename":"Paragraph","id":"c54ad4e0d3ba_43","name":"94d4","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from transformers import BertTokenizer, BertModel\nimport torch","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_44":{"__typename":"Paragraph","id":"c54ad4e0d3ba_44","name":"1fe2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BertTokenizer and BertModel from transformers are used to handle tokenization and obtain embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":18,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":33,"end":45,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_45":{"__typename":"Paragraph","id":"c54ad4e0d3ba_45","name":"81d5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"torch is used for tensor operations.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_46":{"__typename":"Paragraph","id":"c54ad4e0d3ba_46","name":"bbb4","type":"P","href":null,"layout":null,"metadata":null,"text":"2.5.2 Load Pre-trained Model and Tokenizer:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_47":{"__typename":"Paragraph","id":"c54ad4e0d3ba_47","name":"78f3","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Load pre-trained model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_48":{"__typename":"Paragraph","id":"c54ad4e0d3ba_48","name":"192e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"The BertTokenizer and BertModel are initialized with the 'bert-base-uncased' configuration.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":4,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":22,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":57,"end":76,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_49":{"__typename":"Paragraph","id":"c54ad4e0d3ba_49","name":"03ad","type":"P","href":null,"layout":null,"metadata":null,"text":"2.5.3 Define and Tokenize Text:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":30,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_50":{"__typename":"Paragraph","id":"c54ad4e0d3ba_50","name":"fb04","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Define the text\ntext = \"The quick brown fox jumps over the lazy dog.\"\n\n# Tokenize the text\ninputs = tokenizer(text, return_tensors='pt')","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_51":{"__typename":"Paragraph","id":"c54ad4e0d3ba_51","name":"405f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"The text “The quick brown fox jumps over the lazy dog.” is tokenized into tokens suitable for BERT.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_52":{"__typename":"Paragraph","id":"c54ad4e0d3ba_52","name":"207c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"'pt' is used to indicate that tensors should be returned in PyTorch format","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":4,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_53":{"__typename":"Paragraph","id":"c54ad4e0d3ba_53","name":"3ab5","type":"P","href":null,"layout":null,"metadata":null,"text":"2.5.4 Obtain Embeddings:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_54":{"__typename":"Paragraph","id":"c54ad4e0d3ba_54","name":"96be","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Obtain the embeddings\nwith torch.no_grad():\n    outputs = model(**inputs)\n\n# Extract the last hidden state (embeddings)\nlast_hidden_states = outputs.last_hidden_state","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_55":{"__typename":"Paragraph","id":"c54ad4e0d3ba_55","name":"b88f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"The model computes embeddings for the tokenized input text. The torch.no_grad() context is used to avoid gradient calculations, which are not needed during inference.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":64,"end":79,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_56":{"__typename":"Paragraph","id":"c54ad4e0d3ba_56","name":"59ee","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Model Output: When you pass tokenized input through the model with outputs = model(**inputs), the model returns an object that contains several pieces of information, including the last hidden state.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":67,"end":92,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_57":{"__typename":"Paragraph","id":"c54ad4e0d3ba_57","name":"39a7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"outputs.last_hidden_state: This is an attribute of the model output object that contains the hidden states from the last layer of the model. For BERT, this will be a tensor where each token in the input sequence has a vector representation.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_58":{"__typename":"Paragraph","id":"c54ad4e0d3ba_58","name":"8063","type":"P","href":null,"layout":null,"metadata":null,"text":"2.5.5 Print Embeddings:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_59":{"__typename":"Paragraph","id":"c54ad4e0d3ba_59","name":"ead3","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Print the dimensions of the embeddings\nprint(\"Shape of the last hidden state (embeddings):\", last_hidden_states.shape)\n\n# Print embeddings for each token along with their vector dimension\ntokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\nfor token, embedding in zip(tokens, last_hidden_states[0]):\n    print(f\"Token: {token}, Embedding Dimension: {embedding.shape}, Embedding (first 5 components): {embedding[:5]}...\")  # Display first 5 components for brevity","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_60":{"__typename":"Paragraph","id":"c54ad4e0d3ba_60","name":"b4cd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"The shape of the embeddings is displayed to indicate their dimensions. Since we’re using the BERT base model, the vector dimension is 768.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":134,"end":137,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_61":{"__typename":"Paragraph","id":"c54ad4e0d3ba_61","name":"2e15","type":"ULI","href":null,"layout":null,"metadata":null,"text":"For each token in the text, the corresponding embedding is printed along with its dimension and the first 5 components of the embedding vector for brevity.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_62":{"__typename":"Paragraph","id":"c54ad4e0d3ba_62","name":"d6ae","type":"H3","href":null,"layout":null,"metadata":null,"text":"3. Embedding Types","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_63":{"__typename":"Paragraph","id":"c54ad4e0d3ba_63","name":"efa7","type":"P","href":null,"layout":null,"metadata":null,"text":"In natural language processing (NLP), Word Embeddings and Sentence Embeddings represent two different approaches to capturing semantic information from text. In section 2.5 “Embedding Generation — Code Example”, the final outputs consist of word embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":38,"end":53,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":58,"end":77,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_64":{"__typename":"Paragraph","id":"c54ad4e0d3ba_64","name":"3e8d","type":"P","href":null,"layout":null,"metadata":null,"text":"Here’s a brief comparison of the two and their use cases:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_65":{"__typename":"Paragraph","id":"c54ad4e0d3ba_65","name":"832c","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.1 Word Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_66":{"__typename":"Paragraph","id":"c54ad4e0d3ba_66","name":"9ee4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Word embeddings are dense vector representations of individual words. They encode semantic properties and relationships between words.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_67":{"__typename":"Paragraph","id":"c54ad4e0d3ba_67","name":"5125","type":"P","href":null,"layout":null,"metadata":null,"text":"Use Cases of Word Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":28,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_68":{"__typename":"Paragraph","id":"c54ad4e0d3ba_68","name":"9504","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Token classification (e.g., named entity recognition).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_69":{"__typename":"Paragraph","id":"c54ad4e0d3ba_69","name":"cc2d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Contextualizing individual words in a sentence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_70":{"__typename":"Paragraph","id":"c54ad4e0d3ba_70","name":"8b3c","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.2 Sentence Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_71":{"__typename":"Paragraph","id":"c54ad4e0d3ba_71","name":"702a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Sentence embeddings are dense vector representations of entire sentences or documents. They aim to capture the overall meaning of the text rather than individual words.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_72":{"__typename":"Paragraph","id":"c54ad4e0d3ba_72","name":"66dd","type":"P","href":null,"layout":null,"metadata":null,"text":"Use Cases of Sentence Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":32,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_73":{"__typename":"Paragraph","id":"c54ad4e0d3ba_73","name":"4368","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Text similarity search.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_74":{"__typename":"Paragraph","id":"c54ad4e0d3ba_74","name":"0ad6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Sentence classification.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_75":{"__typename":"Paragraph","id":"c54ad4e0d3ba_75","name":"da54","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Document retrieval.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_76":{"__typename":"Paragraph","id":"c54ad4e0d3ba_76","name":"993f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Semantic textual similarity.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_77":{"__typename":"Paragraph","id":"c54ad4e0d3ba_77","name":"a12b","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.3 Methods for Obtaining Sentence Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_78":{"__typename":"Paragraph","id":"c54ad4e0d3ba_78","name":"ef01","type":"P","href":null,"layout":null,"metadata":null,"text":"In sentence embeddings, the goal is to represent an entire sentence or document with a single vector. This can be achieved through various methods.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":85,"end":100,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_79":{"__typename":"Paragraph","id":"c54ad4e0d3ba_79","name":"8879","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Mean Pooling:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_80":{"__typename":"Paragraph","id":"c54ad4e0d3ba_80","name":"70fc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Average the embeddings of all tokens in the sentence to get a single vector representation.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_81":{"__typename":"Paragraph","id":"c54ad4e0d3ba_81","name":"8e71","type":"P","href":null,"layout":null,"metadata":null,"text":"2. [CLS] Token Embedding:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_82":{"__typename":"Paragraph","id":"c54ad4e0d3ba_82","name":"202a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Use the embedding of the [CLS] token from models like BERT as the sentence representation.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":25,"end":30,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_83":{"__typename":"Paragraph","id":"c54ad4e0d3ba_83","name":"c23c","type":"P","href":null,"layout":null,"metadata":null,"text":"3. Pre-trained Sentence Embedding Models:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":40,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_84":{"__typename":"Paragraph","id":"c54ad4e0d3ba_84","name":"f1a2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Models like Sentence-BERT (SBERT) are specifically designed to generate high-quality sentence embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_85":{"__typename":"Paragraph","id":"c54ad4e0d3ba_85","name":"2a64","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.4 In a Nutshell","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_86":{"__typename":"Paragraph","id":"c54ad4e0d3ba_86","name":"8bc0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Word Embeddings: Represent individual tokens and are useful for tasks at the token level.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_87":{"__typename":"Paragraph","id":"c54ad4e0d3ba_87","name":"baab","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Sentence Embeddings: Represent entire sentences or documents, providing a holistic view of the text, and are used for higher-level text analysis tasks.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_88":{"__typename":"Paragraph","id":"c54ad4e0d3ba_88","name":"1210","type":"P","href":null,"layout":null,"metadata":null,"text":"In this article, we focus on text similarity search, so let’s explore how to achieve this next.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":29,"end":51,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_89":{"__typename":"Paragraph","id":"c54ad4e0d3ba_89","name":"366e","type":"H3","href":null,"layout":null,"metadata":null,"text":"4. Text Similarity Search","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_90":{"__typename":"Paragraph","id":"c54ad4e0d3ba_90","name":"6a67","type":"H4","href":null,"layout":null,"metadata":null,"text":"Code Example","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_91":{"__typename":"Paragraph","id":"c54ad4e0d3ba_91","name":"989b","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from transformers import BertTokenizer, BertModel\nimport torch\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load pre-trained model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\ndef get_sentence_embedding(text):\n    inputs = tokenizer(text, return_tensors='pt')\n    with torch.no_grad():\n        outputs = model(**inputs)\n    last_hidden_states = outputs.last_hidden_state\n    sentence_embedding = torch.mean(last_hidden_states, dim=1).numpy()\n    return sentence_embedding\n\n# Example texts\ntexts = [\n    \"The quick brown fox jumps over the lazy dog.\",\n    \"A fast brown fox leaps over a sleepy dog.\",\n    \"This sentence is completely different from the others.\"\n]\n\n# Generate embeddings for texts\nembeddings = [get_sentence_embedding(text) for text in texts]\n\n# Query text\nquery_text = \"The quick red fox jumps over the lazy dog.\"\nquery_embedding = get_sentence_embedding(query_text)\n\n# Compute cosine similarities\nsimilarities = cosine_similarity(query_embedding, np.vstack(embeddings))\n\n# Print query text\nprint (f\"Query text: {query_text}\")\n\n# Print similarities\nfor i, text in enumerate(texts):\n    print(f\"Similarity with '{text}': {similarities[0][i]}\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_92":{"__typename":"Paragraph","id":"c54ad4e0d3ba_92","name":"0467","type":"P","href":null,"layout":null,"metadata":null,"text":"Output:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_93":{"__typename":"Paragraph","id":"c54ad4e0d3ba_93","name":"d4f6","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Query text: The quick red fox jumps over the lazy dog.\nSimilarity with 'The quick brown fox jumps over the lazy dog.': 0.9852557182312012\nSimilarity with 'A fast brown fox leaps over a sleepy dog.': 0.9026964902877808\nSimilarity with 'This sentence is completely different from the others.': 0.48106062412261963","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_94":{"__typename":"Paragraph","id":"c54ad4e0d3ba_94","name":"4af2","type":"H4","href":null,"layout":null,"metadata":null,"text":"Code Walkthrough","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_95":{"__typename":"Paragraph","id":"c54ad4e0d3ba_95","name":"f31c","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.1 Imports Libraries:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_96":{"__typename":"Paragraph","id":"c54ad4e0d3ba_96","name":"b3df","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from transformers import BertTokenizer, BertModel\nimport torch\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_97":{"__typename":"Paragraph","id":"c54ad4e0d3ba_97","name":"c1d8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BertTokenizer and BertModel from transformers for tokenization and embedding generation.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":18,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":33,"end":45,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_98":{"__typename":"Paragraph","id":"c54ad4e0d3ba_98","name":"72f3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"torch for tensor operations.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_99":{"__typename":"Paragraph","id":"c54ad4e0d3ba_99","name":"e9d8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"numpy and cosine_similarity from sklearn for similarity calculations.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":10,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":33,"end":40,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_100":{"__typename":"Paragraph","id":"c54ad4e0d3ba_100","name":"96bc","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.2 Load Pre-trained Model:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_101":{"__typename":"Paragraph","id":"c54ad4e0d3ba_101","name":"1ebc","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Load pre-trained BERT model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_102":{"__typename":"Paragraph","id":"c54ad4e0d3ba_102","name":"cae7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Initializes BERT tokenizer and model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_103":{"__typename":"Paragraph","id":"c54ad4e0d3ba_103","name":"96d4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BERT base model (uncased) is used.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_104":{"__typename":"Paragraph","id":"c54ad4e0d3ba_104","name":"116d","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.3 Define get_sentence_embedding Function:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":11,"end":33,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_105":{"__typename":"Paragraph","id":"c54ad4e0d3ba_105","name":"1a8b","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Function to get sentence embedding\ndef get_sentence_embedding(text):\n    inputs = tokenizer(text, return_tensors='pt')  # Tokenize and prepare input tensors\n    with torch.no_grad():  # Disable gradient calculation\n        outputs = model(**inputs)  # Get model outputs\n    last_hidden_states = outputs.last_hidden_state  # Extract last hidden states\n    sentence_embedding = torch.mean(last_hidden_states, dim=1).numpy()  # Average token embeddings\n    return sentence_embedding","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_106":{"__typename":"Paragraph","id":"c54ad4e0d3ba_106","name":"bc03","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Takes a text input, tokenizes it, and generates embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_107":{"__typename":"Paragraph","id":"c54ad4e0d3ba_107","name":"92c8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Averages the token embeddings to produce a sentence embedding, using Mean Pooling method.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":69,"end":89,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_108":{"__typename":"Paragraph","id":"c54ad4e0d3ba_108","name":"eb6f","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.4 Generate Embeddings from a list of sentences:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":49,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_109":{"__typename":"Paragraph","id":"c54ad4e0d3ba_109","name":"ba8c","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Example sentences\ntexts = [\n    \"The quick brown fox jumps over the lazy dog.\",\n    \"A fast brown fox leaps over a sleepy dog.\",\n    \"This sentence is completely different from the others.\"\n]\n\n# Generate embeddings for each example sentence\nembeddings = [get_sentence_embedding(text) for text in texts]","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_110":{"__typename":"Paragraph","id":"c54ad4e0d3ba_110","name":"5f75","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Computes embeddings for each sentence in the list.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_111":{"__typename":"Paragraph","id":"c54ad4e0d3ba_111","name":"67cc","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.5 Set Query Text and Compute the Embedding:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":34,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_112":{"__typename":"Paragraph","id":"c54ad4e0d3ba_112","name":"f817","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Query sentence\nquery_text = \"The quick red fox jumps over the lazy dog.\"\nquery_embedding = get_sentence_embedding(query_text)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_113":{"__typename":"Paragraph","id":"c54ad4e0d3ba_113","name":"786c","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.6 Compute Cosine Similarities:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_114":{"__typename":"Paragraph","id":"c54ad4e0d3ba_114","name":"20f1","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Compute cosine similarities between query and example sentences\nsimilarities = cosine_similarity(query_embedding, np.vstack(embeddings))","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_115":{"__typename":"Paragraph","id":"c54ad4e0d3ba_115","name":"e6bb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Measures the similarity between the query embedding and each sentence embedding.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_116":{"__typename":"Paragraph","id":"c54ad4e0d3ba_116","name":"e600","type":"ULI","href":null,"layout":null,"metadata":null,"text":"The cosine distance method is used to measure the distance or similarity between two vectors based on the cosine of the angle between them. It is commonly employed in text similarity and clustering tasks due to its effectiveness in handling high-dimensional data.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_117":{"__typename":"Paragraph","id":"c54ad4e0d3ba_117","name":"7e58","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.7 Print Results:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_118":{"__typename":"Paragraph","id":"c54ad4e0d3ba_118","name":"dbe7","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Print query text\nprint(f\"Query text: {query_text}\")\n\n# Print similarity scores\nfor i, text in enumerate(texts):\n    print(f\"Similarity with '{text}': {similarities[0][i]}\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_119":{"__typename":"Paragraph","id":"c54ad4e0d3ba_119","name":"7d6b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Displays the query text and its similarity scores with the example sentences.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_120":{"__typename":"Paragraph","id":"c54ad4e0d3ba_120","name":"af63","type":"H3","href":null,"layout":null,"metadata":null,"text":"5. Model Size and Vector Dimension","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_121":{"__typename":"Paragraph","id":"c54ad4e0d3ba_121","name":"8909","type":"P","href":null,"layout":null,"metadata":null,"text":"Model Size and Vector Dimension are key aspects in understanding the capabilities and computational requirements of modern NLP models like GPT, BERT, and similar architectures.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":15,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_122":{"__typename":"Paragraph","id":"c54ad4e0d3ba_122","name":"75bd","type":"H4","href":null,"layout":null,"metadata":null,"text":"5.1 Model Size","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_123":{"__typename":"Paragraph","id":"c54ad4e0d3ba_123","name":"7f88","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Definition: Model size refers to the total number of parameters in a machine learning model. Parameters are the elements of the model that are learned from the training data, including weights and biases. The model size directly impacts its capacity to learn from and generalize to new data.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_124":{"__typename":"Paragraph","id":"c54ad4e0d3ba_124","name":"a178","type":"P","href":null,"layout":null,"metadata":null,"text":"Examples:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_125":{"__typename":"Paragraph","id":"c54ad4e0d3ba_125","name":"c0a4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BERT: The base model has 110 million parameters, while the large model has 340 million parameters. These parameters allow BERT to learn nuanced language representations across various contexts.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":4,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_126":{"__typename":"Paragraph","id":"c54ad4e0d3ba_126","name":"fb3c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GPT-3: With 175 billion parameters, GPT-3 represents one of the largest models to date, capable of generating highly coherent and contextually relevant text across a wide range of topics.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_127":{"__typename":"Paragraph","id":"c54ad4e0d3ba_127","name":"2ed7","type":"H4","href":null,"layout":null,"metadata":null,"text":"5.2 Vector Dimension","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_128":{"__typename":"Paragraph","id":"c54ad4e0d3ba_128","name":"9033","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Definition: Vector dimension refers to the length of the vectors used to represent tokens, sentences, or documents in the model’s embedding space. This dimension determines the number of features or attributes captured in the embedding vectors.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_129":{"__typename":"Paragraph","id":"c54ad4e0d3ba_129","name":"b261","type":"P","href":null,"layout":null,"metadata":null,"text":"Examples:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_130":{"__typename":"Paragraph","id":"c54ad4e0d3ba_130","name":"7e8d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BERT: The base model produces 768-dimensional embeddings for each token, while the large model produces 1024-dimensional embeddings. This dimensionality helps capture detailed contextual information for each token in the text.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":4,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_131":{"__typename":"Paragraph","id":"c54ad4e0d3ba_131","name":"1cc6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GPT-3: Uses 12288-dimensional embeddings for its internal representations, reflecting its capacity to model complex language patterns and contexts.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_132":{"__typename":"Paragraph","id":"c54ad4e0d3ba_132","name":"37c9","type":"H3","href":null,"layout":null,"metadata":null,"text":"6. Steps After Text Embedding Generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_133":{"__typename":"Paragraph","id":"c54ad4e0d3ba_133","name":"6bf4","type":"P","href":null,"layout":null,"metadata":null,"text":"After generating embeddings with a pre-trained model, further steps are needed for practical application in real-world scenarios. These steps include preparing datasets, indexing embeddings for efficient retrieval, using vector databases for storage and vector search, deploying the model, and performing ongoing maintenance.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":108,"end":128,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":150,"end":168,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":170,"end":189,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":221,"end":237,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":254,"end":267,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_134":{"__typename":"Paragraph","id":"c54ad4e0d3ba_134","name":"e660","type":"P","href":null,"layout":null,"metadata":null,"text":"In upcoming articles, we will explore these topics in greater detail.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":3,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_135":{"__typename":"Paragraph","id":"c54ad4e0d3ba_135","name":"3790","type":"H3","href":null,"layout":null,"metadata":null,"text":"Summary","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_136":{"__typename":"Paragraph","id":"c54ad4e0d3ba_136","name":"4980","type":"P","href":null,"layout":null,"metadata":null,"text":"Contextual embeddings have revolutionized NLP by providing richer text representations. This guide explains the theory behind embeddings, tokenization, and generating embeddings with models like BERT. It also covers methods for obtaining sentence embeddings and the impact of model size and vector dimensions. Further steps, including dataset preparation and vector database search, are crucial for real-world applications, which will be explored in future articles.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":335,"end":354,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":359,"end":381,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_137":{"__typename":"Paragraph","id":"c54ad4e0d3ba_137","name":"9c28","type":"H3","href":null,"layout":null,"metadata":null,"text":"You May Also Like","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:c54ad4e0d3ba_138":{"__typename":"Paragraph","id":"c54ad4e0d3ba_138","name":"036c","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"Guide — Getting Started with Cursor and DeepSeek R1\nFirst Steps in AI-Powered Coding: A Beginner’s Guidemedium.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":114,"href":"https:\u002F\u002Fmedium.com\u002F@davidlfliang\u002Fguide-getting-started-with-cursor-and-deepseek-r1-710a75138566","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":51,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":52,"end":104,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fmedium.com\u002F@davidlfliang\u002Fguide-getting-started-with-cursor-and-deepseek-r1-710a75138566","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"1*JXnjxfx0wxr5U2VFMeITgQ.png"}},"UserViewerEdge:userId:edc72cb1fd52-viewerId:lo_8e52d96f0d22":{"__typename":"UserViewerEdge","id":"userId:edc72cb1fd52-viewerId:lo_8e52d96f0d22","isMuting":false},"PostViewerEdge:postId:9f8c3b98dee6-viewerId:lo_8e52d96f0d22":{"__typename":"PostViewerEdge","shouldIndexPostForExternalSearch":true,"id":"postId:9f8c3b98dee6-viewerId:lo_8e52d96f0d22"},"Tag:bert":{"__typename":"Tag","id":"bert","displayTitle":"Bert","normalizedTagSlug":"bert"},"Tag:text-embedding":{"__typename":"Tag","id":"text-embedding","displayTitle":"Text Embedding","normalizedTagSlug":"text-embedding"},"Tag:python":{"__typename":"Tag","id":"python","displayTitle":"Python","normalizedTagSlug":"python"},"Tag:vector-search":{"__typename":"Tag","id":"vector-search","displayTitle":"Vector Search","normalizedTagSlug":"vector-search"},"Tag:similarity-search":{"__typename":"Tag","id":"similarity-search","displayTitle":"Similarity Search","normalizedTagSlug":"similarity-search"},"Post:9f8c3b98dee6":{"__typename":"Post","id":"9f8c3b98dee6","collection":null,"content({\"postMeteringOptions\":{\"referrer\":\"\"}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"ad32","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"e729","startIndex":137,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:c54ad4e0d3ba_0"},{"__ref":"Paragraph:c54ad4e0d3ba_1"},{"__ref":"Paragraph:c54ad4e0d3ba_2"},{"__ref":"Paragraph:c54ad4e0d3ba_3"},{"__ref":"Paragraph:c54ad4e0d3ba_4"},{"__ref":"Paragraph:c54ad4e0d3ba_5"},{"__ref":"Paragraph:c54ad4e0d3ba_6"},{"__ref":"Paragraph:c54ad4e0d3ba_7"},{"__ref":"Paragraph:c54ad4e0d3ba_8"},{"__ref":"Paragraph:c54ad4e0d3ba_9"},{"__ref":"Paragraph:c54ad4e0d3ba_10"},{"__ref":"Paragraph:c54ad4e0d3ba_11"},{"__ref":"Paragraph:c54ad4e0d3ba_12"},{"__ref":"Paragraph:c54ad4e0d3ba_13"},{"__ref":"Paragraph:c54ad4e0d3ba_14"},{"__ref":"Paragraph:c54ad4e0d3ba_15"},{"__ref":"Paragraph:c54ad4e0d3ba_16"},{"__ref":"Paragraph:c54ad4e0d3ba_17"},{"__ref":"Paragraph:c54ad4e0d3ba_18"},{"__ref":"Paragraph:c54ad4e0d3ba_19"},{"__ref":"Paragraph:c54ad4e0d3ba_20"},{"__ref":"Paragraph:c54ad4e0d3ba_21"},{"__ref":"Paragraph:c54ad4e0d3ba_22"},{"__ref":"Paragraph:c54ad4e0d3ba_23"},{"__ref":"Paragraph:c54ad4e0d3ba_24"},{"__ref":"Paragraph:c54ad4e0d3ba_25"},{"__ref":"Paragraph:c54ad4e0d3ba_26"},{"__ref":"Paragraph:c54ad4e0d3ba_27"},{"__ref":"Paragraph:c54ad4e0d3ba_28"},{"__ref":"Paragraph:c54ad4e0d3ba_29"},{"__ref":"Paragraph:c54ad4e0d3ba_30"},{"__ref":"Paragraph:c54ad4e0d3ba_31"},{"__ref":"Paragraph:c54ad4e0d3ba_32"},{"__ref":"Paragraph:c54ad4e0d3ba_33"},{"__ref":"Paragraph:c54ad4e0d3ba_34"},{"__ref":"Paragraph:c54ad4e0d3ba_35"},{"__ref":"Paragraph:c54ad4e0d3ba_36"},{"__ref":"Paragraph:c54ad4e0d3ba_37"},{"__ref":"Paragraph:c54ad4e0d3ba_38"},{"__ref":"Paragraph:c54ad4e0d3ba_39"},{"__ref":"Paragraph:c54ad4e0d3ba_40"},{"__ref":"Paragraph:c54ad4e0d3ba_41"},{"__ref":"Paragraph:c54ad4e0d3ba_42"},{"__ref":"Paragraph:c54ad4e0d3ba_43"},{"__ref":"Paragraph:c54ad4e0d3ba_44"},{"__ref":"Paragraph:c54ad4e0d3ba_45"},{"__ref":"Paragraph:c54ad4e0d3ba_46"},{"__ref":"Paragraph:c54ad4e0d3ba_47"},{"__ref":"Paragraph:c54ad4e0d3ba_48"},{"__ref":"Paragraph:c54ad4e0d3ba_49"},{"__ref":"Paragraph:c54ad4e0d3ba_50"},{"__ref":"Paragraph:c54ad4e0d3ba_51"},{"__ref":"Paragraph:c54ad4e0d3ba_52"},{"__ref":"Paragraph:c54ad4e0d3ba_53"},{"__ref":"Paragraph:c54ad4e0d3ba_54"},{"__ref":"Paragraph:c54ad4e0d3ba_55"},{"__ref":"Paragraph:c54ad4e0d3ba_56"},{"__ref":"Paragraph:c54ad4e0d3ba_57"},{"__ref":"Paragraph:c54ad4e0d3ba_58"},{"__ref":"Paragraph:c54ad4e0d3ba_59"},{"__ref":"Paragraph:c54ad4e0d3ba_60"},{"__ref":"Paragraph:c54ad4e0d3ba_61"},{"__ref":"Paragraph:c54ad4e0d3ba_62"},{"__ref":"Paragraph:c54ad4e0d3ba_63"},{"__ref":"Paragraph:c54ad4e0d3ba_64"},{"__ref":"Paragraph:c54ad4e0d3ba_65"},{"__ref":"Paragraph:c54ad4e0d3ba_66"},{"__ref":"Paragraph:c54ad4e0d3ba_67"},{"__ref":"Paragraph:c54ad4e0d3ba_68"},{"__ref":"Paragraph:c54ad4e0d3ba_69"},{"__ref":"Paragraph:c54ad4e0d3ba_70"},{"__ref":"Paragraph:c54ad4e0d3ba_71"},{"__ref":"Paragraph:c54ad4e0d3ba_72"},{"__ref":"Paragraph:c54ad4e0d3ba_73"},{"__ref":"Paragraph:c54ad4e0d3ba_74"},{"__ref":"Paragraph:c54ad4e0d3ba_75"},{"__ref":"Paragraph:c54ad4e0d3ba_76"},{"__ref":"Paragraph:c54ad4e0d3ba_77"},{"__ref":"Paragraph:c54ad4e0d3ba_78"},{"__ref":"Paragraph:c54ad4e0d3ba_79"},{"__ref":"Paragraph:c54ad4e0d3ba_80"},{"__ref":"Paragraph:c54ad4e0d3ba_81"},{"__ref":"Paragraph:c54ad4e0d3ba_82"},{"__ref":"Paragraph:c54ad4e0d3ba_83"},{"__ref":"Paragraph:c54ad4e0d3ba_84"},{"__ref":"Paragraph:c54ad4e0d3ba_85"},{"__ref":"Paragraph:c54ad4e0d3ba_86"},{"__ref":"Paragraph:c54ad4e0d3ba_87"},{"__ref":"Paragraph:c54ad4e0d3ba_88"},{"__ref":"Paragraph:c54ad4e0d3ba_89"},{"__ref":"Paragraph:c54ad4e0d3ba_90"},{"__ref":"Paragraph:c54ad4e0d3ba_91"},{"__ref":"Paragraph:c54ad4e0d3ba_92"},{"__ref":"Paragraph:c54ad4e0d3ba_93"},{"__ref":"Paragraph:c54ad4e0d3ba_94"},{"__ref":"Paragraph:c54ad4e0d3ba_95"},{"__ref":"Paragraph:c54ad4e0d3ba_96"},{"__ref":"Paragraph:c54ad4e0d3ba_97"},{"__ref":"Paragraph:c54ad4e0d3ba_98"},{"__ref":"Paragraph:c54ad4e0d3ba_99"},{"__ref":"Paragraph:c54ad4e0d3ba_100"},{"__ref":"Paragraph:c54ad4e0d3ba_101"},{"__ref":"Paragraph:c54ad4e0d3ba_102"},{"__ref":"Paragraph:c54ad4e0d3ba_103"},{"__ref":"Paragraph:c54ad4e0d3ba_104"},{"__ref":"Paragraph:c54ad4e0d3ba_105"},{"__ref":"Paragraph:c54ad4e0d3ba_106"},{"__ref":"Paragraph:c54ad4e0d3ba_107"},{"__ref":"Paragraph:c54ad4e0d3ba_108"},{"__ref":"Paragraph:c54ad4e0d3ba_109"},{"__ref":"Paragraph:c54ad4e0d3ba_110"},{"__ref":"Paragraph:c54ad4e0d3ba_111"},{"__ref":"Paragraph:c54ad4e0d3ba_112"},{"__ref":"Paragraph:c54ad4e0d3ba_113"},{"__ref":"Paragraph:c54ad4e0d3ba_114"},{"__ref":"Paragraph:c54ad4e0d3ba_115"},{"__ref":"Paragraph:c54ad4e0d3ba_116"},{"__ref":"Paragraph:c54ad4e0d3ba_117"},{"__ref":"Paragraph:c54ad4e0d3ba_118"},{"__ref":"Paragraph:c54ad4e0d3ba_119"},{"__ref":"Paragraph:c54ad4e0d3ba_120"},{"__ref":"Paragraph:c54ad4e0d3ba_121"},{"__ref":"Paragraph:c54ad4e0d3ba_122"},{"__ref":"Paragraph:c54ad4e0d3ba_123"},{"__ref":"Paragraph:c54ad4e0d3ba_124"},{"__ref":"Paragraph:c54ad4e0d3ba_125"},{"__ref":"Paragraph:c54ad4e0d3ba_126"},{"__ref":"Paragraph:c54ad4e0d3ba_127"},{"__ref":"Paragraph:c54ad4e0d3ba_128"},{"__ref":"Paragraph:c54ad4e0d3ba_129"},{"__ref":"Paragraph:c54ad4e0d3ba_130"},{"__ref":"Paragraph:c54ad4e0d3ba_131"},{"__ref":"Paragraph:c54ad4e0d3ba_132"},{"__ref":"Paragraph:c54ad4e0d3ba_133"},{"__ref":"Paragraph:c54ad4e0d3ba_134"},{"__ref":"Paragraph:c54ad4e0d3ba_135"},{"__ref":"Paragraph:c54ad4e0d3ba_136"},{"__ref":"Paragraph:c54ad4e0d3ba_137"},{"__ref":"Paragraph:c54ad4e0d3ba_138"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:edc72cb1fd52"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@davidlfliang\u002Fintro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6","primaryTopic":null,"topics":[{"__typename":"Topic","slug":"machine-learning"}],"isLimitedState":false,"isPublished":true,"allowResponses":true,"responsesLocked":false,"visibility":"PUBLIC","latestPublishedVersion":"c54ad4e0d3ba","postResponses":{"__typename":"PostResponses","count":0},"responseDistribution":"NOT_DISTRIBUTED","clapCount":4,"title":"Intro — Getting Started with Text Embeddings: Using BERT","isSeries":false,"sequence":null,"uniqueSlug":"intro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6","socialTitle":"","socialDek":"","canonicalUrl":"","metaDescription":"","latestPublishedAt":1740724073925,"readingTime":9.969811320754717,"previewContent":{"__typename":"PreviewContent","subtitle":"Contextual embeddings have revolutionized natural language processing (NLP) by providing richer, context-aware representations of text…"},"previewImage":{"__ref":"ImageMetadata:1*7qIA2ypzDmgjpRIQX-ICmQ.jpeg"},"isShortform":false,"seoTitle":"","firstPublishedAt":1722337038122,"updatedAt":1740727695208,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","viewerEdge":{"__ref":"PostViewerEdge:postId:9f8c3b98dee6-viewerId:lo_8e52d96f0d22"},"isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:bert"},{"__ref":"Tag:text-embedding"},{"__ref":"Tag:python"},{"__ref":"Tag:vector-search"},{"__ref":"Tag:similarity-search"}],"isFeaturedInPublishedPublication":false,"isNewsletter":false,"statusForCollection":null,"pendingCollection":null,"detectedLanguage":"en","wordCount":2589,"layerCake":0}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT"}}</script><script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/manifest.5991cf1e.js"></script><script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/4783.3b00fa4a.js"></script><script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/main.70c9d90e.js"></script><script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/instrumentation.5bef8967.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/reporting.ff22a7a5.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/3171.5b0ceee8.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/628.4b410354.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/6618.db187378.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/3338.0505d492.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/2707.e49411e8.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/9977.3cee8988.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/7465.cf88931d.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/4737.5256e883.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/7381.9944134b.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/6372.7118269b.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/7938.4f8e1aff.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/3862.b8166914.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/3054.3f2efcff.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/4929.37d2472b.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/3623.bc669f38.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/7979.15bcd496.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/7975.d44b0cb9.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/6834.aa1899a4.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/8664.b06e2cc0.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/4378.6c27319c.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/144.64ea10bb.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/3666.cdb15b43.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/8768.516b8cf0.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/1069.499eaa23.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/3523.4da37341.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/PostPage.MainContent.9b253805.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/2698.a5c8f865.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/3974.6ff9e2e8.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/2527.19bcbbd2.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/PostResponsesContent.9bd6b113.chunk.js"></script>
<script src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/responses.editor.ec13f6ad.chunk.js"></script><script>window.main();</script><script defer="defer" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/vcd15cbe7772f49c399c6a5babf22c1241717689176015.js" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon="{&quot;rayId&quot;:&quot;92b6ae058ab5e65d&quot;,&quot;serverTiming&quot;:{&quot;name&quot;:{&quot;cfExtPri&quot;:true,&quot;cfL4&quot;:true,&quot;cfSpeedBrain&quot;:true,&quot;cfCacheStatus&quot;:true}},&quot;version&quot;:&quot;2025.3.0&quot;,&quot;token&quot;:&quot;0b5f665943484354a59c39c6833f7078&quot;}" crossorigin="anonymous"></script>
<div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" width="256" height="60" role="presentation" name="a-lwccd0feluvs" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="Intro%20%E2%80%94%20Getting%20Started%20with%20Text%20Embeddings_%20Using%20BERT%20_%20by%20David%20Liang%20_%20Medium_files/anchor.html"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;"></iframe></div></body></html>